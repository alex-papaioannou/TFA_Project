{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/alexpapaioannou/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/alexpapaioannou/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: profanity-check in /Users/alexpapaioannou/anaconda3/lib/python3.7/site-packages (1.0.2)\n",
      "Requirement already satisfied: scikit-learn==0.20.2 in /Users/alexpapaioannou/anaconda3/lib/python3.7/site-packages (from profanity-check) (0.20.2)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /Users/alexpapaioannou/anaconda3/lib/python3.7/site-packages (from scikit-learn==0.20.2->profanity-check) (1.16.2)\n",
      "Requirement already satisfied: scipy>=0.13.3 in /Users/alexpapaioannou/anaconda3/lib/python3.7/site-packages (from scikit-learn==0.20.2->profanity-check) (1.2.1)\n",
      "Collecting filelock\n",
      "  Using cached https://files.pythonhosted.org/packages/d7/ca/3c74396a9ed8a4cfab5459800edeef9a1269591cb21f5a49bd71a49c5fa2/filelock-3.0.10-py3-none-any.whl\n",
      "Installing collected packages: filelock\n",
      "Successfully installed filelock-3.0.10\n",
      "Collecting coverage\n",
      "  Using cached https://files.pythonhosted.org/packages/a8/39/5334b42cc81a40d50901eca26f4fac4480b44ac318db55d2b621d0aaca09/coverage-4.5.3-cp37-cp37m-macosx_10_13_x86_64.whl\n",
      "Installing collected packages: coverage\n",
      "Successfully installed coverage-4.5.3\n",
      "Requirement already satisfied: langdetect in /Users/alexpapaioannou/anaconda3/lib/python3.7/site-packages (1.0.7)\n",
      "Requirement already satisfied: six in /Users/alexpapaioannou/anaconda3/lib/python3.7/site-packages (from langdetect) (1.12.0)\n",
      "Requirement already satisfied: googletrans in /Users/alexpapaioannou/anaconda3/lib/python3.7/site-packages (2.4.0)\n",
      "Requirement already satisfied: requests in /Users/alexpapaioannou/anaconda3/lib/python3.7/site-packages (from googletrans) (2.21.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/alexpapaioannou/anaconda3/lib/python3.7/site-packages (from requests->googletrans) (2.8)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /Users/alexpapaioannou/anaconda3/lib/python3.7/site-packages (from requests->googletrans) (1.24.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/alexpapaioannou/anaconda3/lib/python3.7/site-packages (from requests->googletrans) (2019.3.9)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/alexpapaioannou/anaconda3/lib/python3.7/site-packages (from requests->googletrans) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# environment setting\n",
    "# import pandas as pd\n",
    "# import sqlite3\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.backends.backend_pdf import PdfPages\n",
    "# %matplotlib inline\n",
    "\n",
    "# plt.rc(\"font\", size=16)\n",
    "# import seaborn as sns\n",
    "# sns.set(style=\"white\")\n",
    "# sns.set(style=\"whitegrid\", color_codes=True)\n",
    "\n",
    "import uuid\n",
    "import requests\n",
    "from googletrans import Translator\n",
    "from langdetect import detect\n",
    "import argparse\n",
    "from profanity_check import predict, predict_prob\n",
    "import os\n",
    "import os.path\n",
    "import glob\n",
    "import re\n",
    "\n",
    "import json\n",
    "import time\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk.data\n",
    "nltk.downloader.download('vader_lexicon')\n",
    "nltk.downloader.download('stopwords')\n",
    "\n",
    "! pip install profanity-check\n",
    "# https://github.com/vzhou842/profanity-check\n",
    "\n",
    "!pip install filelock --ignore-installed\n",
    "\n",
    "\n",
    "!pip install coverage --ignore-installed\n",
    "\n",
    "!pip install langdetect\n",
    "\n",
    "!pip install googletrans\n",
    "translator = Translator()\n",
    "\n",
    "# !pip install py-translator\n",
    "# from py_translator import Translator\n",
    "\n",
    "# !pip install translate\n",
    "# from translate import Translator\n",
    "# translator = Translator(to_lang='en')\n",
    "\n",
    "# import goslate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/alexpapaioannou/Dropbox/Personal Things/Personal/Studies Related/NY/COLUMBIA UNIVERSITY/IEOR/MSMSE/Courses/IEOR 4501 E 001 TOOLS FOR ANALYTICS/TOOLS_2019/Project_2019/Lyrics/Flaming-Ember'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-95f1d765cb50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m \u001b[0msong_cleaning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0martist_s_cleaned_songs_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-60-95f1d765cb50>\u001b[0m in \u001b[0;36msong_cleaning\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msong\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martist_s_songs_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mwords_of_lyrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mfin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_given\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mr'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m             \u001b[0mraw_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/alexpapaioannou/Dropbox/Personal Things/Personal/Studies Related/NY/COLUMBIA UNIVERSITY/IEOR/MSMSE/Courses/IEOR 4501 E 001 TOOLS FOR ANALYTICS/TOOLS_2019/Project_2019/Lyrics/Flaming-Ember'"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "# parser = argparse.ArgumentParser('Parses the given directory of lyrics')\n",
    "# parser.add_argument('dir_given', help='Directory of the lyrics')\n",
    "# args = parser.parse_args()\n",
    "# dir_given = args.dir_given\n",
    "\n",
    "# Simulated 'Given' directory, needs to be changed to input from command line kss0416\n",
    "\n",
    "\n",
    "def dir_given():\n",
    "    return r'/Users/alexpapaioannou/Dropbox/Personal Things/Personal/Studies Related/NY/COLUMBIA UNIVERSITY/IEOR/MSMSE/Courses/IEOR 4501 E 001 TOOLS FOR ANALYTICS/TOOLS_2019/Project_2019/Lyrics'\n",
    "\n",
    "\n",
    "dir_given = '/Users/alexpapaioannou/Dropbox/Personal Things/Personal/Studies Related/NY/COLUMBIA UNIVERSITY/IEOR/MSMSE/Courses/IEOR 4501 E 001 TOOLS FOR ANALYTICS/TOOLS_2019/Project_2019/Lyrics'\n",
    "os.chdir(dir_given)\n",
    "\n",
    "def artists_list() -> list:\n",
    "    artists_list_ = []\n",
    "    for raw_filename in os.listdir(dir_given):\n",
    "        if raw_filename.endswith('.txt'):\n",
    "            try:\n",
    "                artist_name = raw_filename.split(\"~\")[1].split(\"~\")[0]\n",
    "                if artist_name not in artists_list_:\n",
    "                    artists_list_.append(artist_name)\n",
    "            except IndexError:\n",
    "                pass\n",
    "    return artists_list_\n",
    "\n",
    "\n",
    "def raw_filenames_list() -> list:\n",
    "    raw_filenames_list_ = []\n",
    "    for raw_filename in os.listdir(dir_given):\n",
    "        if raw_filename.endswith('.txt'):\n",
    "            raw_filenames_list_.append(raw_filename)\n",
    "    return raw_filenames_list_\n",
    "\n",
    "\n",
    "def artist_s_songs_list(str) -> list:\n",
    "    artist_s_songs_list_ = []\n",
    "    for raw_filename in raw_filenames_list():\n",
    "        if str in raw_filename:\n",
    "            artist_s_songs_list_.append(str)\n",
    "    return artist_s_songs_list_\n",
    "\n",
    "\n",
    "def song_cleaning():\n",
    "    try:\n",
    "        os.mkdir(dir_given + '/Cleaned_Songs/')\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "    for artist in set(artists_list()):\n",
    "        for song in artist_s_songs_list(artist):\n",
    "            words_of_lyrics = []\n",
    "            fin = open(dir_given + r'/' + song, 'rb')\n",
    "            raw_text = \"\"\n",
    "            for line in fin.readlines():    \n",
    "                # remove empty lines\n",
    "                this_line_wordlist = line.decode('utf-8').split()\n",
    "                for word in this_line_wordlist:\n",
    "                    words_of_lyrics.append(word)\n",
    "            for word_ in words_of_lyrics:\n",
    "                raw_text += word_+\" \"\n",
    "            # remove identifiers like chorus, verse, etc\n",
    "            raw_text = re.sub(r'[\\(\\[].*[\\)\\]]', '', raw_text)\n",
    "            # remove punctuation\n",
    "            raw_text = re.sub(r'[^\\w\\s]', '', raw_text)\n",
    "            fout = open(os.path.join(dir_given +\n",
    "                                  '/Cleaned_Songs', 'cleaned_' + song), \"wb\")\n",
    "            fout.write(raw_text.encode('utf-8'))\n",
    "            fin.close()\n",
    "            fout.close()\n",
    "    return\n",
    "\n",
    "song_cleaning()\n",
    "\n",
    "def artist_s_cleaned_songs_list(str) -> list:\n",
    "    artist_s_cleaned_songs_list_ = []\n",
    "    for cleaned_raw_filename in os.listdir(dir_given + '/Cleaned_Songs/'):\n",
    "        if cleaned_raw_filename.endswith(str + '.txt') is True:\n",
    "            if cleaned_raw_filename.endswith(str + '.txt') not in artist_s_cleaned_songs_list_:\n",
    "                artist_s_cleaned_songs_list_.append(cleaned_raw_filename)\n",
    "    return artist_s_cleaned_songs_list_\n",
    "\n",
    "\n",
    "# def song_translating(artists_list):\n",
    "#     cleaned_songs_directory = dir_given + \"/Cleaned_Songs/\"\n",
    "#     for artist in artists_list:\n",
    "#         for song in artist_s_songs_list(artist):\n",
    "#             try:\n",
    "#                 if translator.detect(this_sentence).lang == 'en':\n",
    "#                     pass\n",
    "#                 else:\n",
    "#                     f = open(cleaned_songs_directory + 'cleaned_' + song, 'rb')\n",
    "#                     all_words = ''\n",
    "#                     for sentence in f.readlines():\n",
    "#                         this_sentence = sentence.decode('utf-8')\n",
    "#                         translation = translator.translate(this_sentence)\n",
    "#                         all_words += translation.text\n",
    "#                     print(song)\n",
    "#                     print(all_words)\n",
    "#                     f.write(all_words.encode('utf-8'))\n",
    "#                     f.close()\n",
    "#             except:\n",
    "#                 print('exception')\n",
    "#     return\n",
    "\n",
    "# song_translating(artists_list())\n",
    "\n",
    "# def song_translating(artists_list):\n",
    "#     for artist in set(artists_list):\n",
    "#         for song in artist_s_songs_list(artist):\n",
    "#             #Changed below to base on single given directory\n",
    "#             f = open(dir_given + r'/Cleaned_Songs/cleaned_' +  song, 'rb')\n",
    "#             all_words = ''\n",
    "#             cleaned_songs_directory = dir_given + \"/Cleaned_Songs/\"\n",
    "\n",
    "#             for sentence in f.readlines():\n",
    "#                 this_sentence = sentence.decode('utf-8')\n",
    "#                 try:\n",
    "#                     if translator.detect(this_sentence).lang == 'en':\n",
    "#                         all_words += this_sentence\n",
    "#                     else:\n",
    "#                         translation = translator.translate(this_sentence)\n",
    "#                         all_words += translation.text\n",
    "#                 except:\n",
    "#                     print('exception')\n",
    "#             f = open(cleaned_songs_directory + 'cleaned_' + song, 'wb')\n",
    "#             f.write(all_words.encode('utf-8'))\n",
    "#             f.close()\n",
    "#     return\n",
    "\n",
    "# song_translating(artists_list())\n",
    "\n",
    "\n",
    "def id_song_to_be_scored(song_to_be_scored):\n",
    "\n",
    "    pattern = re.compile(\n",
    "        r'(cleaned_)(?P<id>[\\d\\D]+)(~)(?P<song_title>[\\d\\D]+)(~)(?P<artist_name>[\\d\\D]+)(.txt)')\n",
    "    match = pattern.match(song_to_be_scored)\n",
    "    try:\n",
    "        id_ = match.group('id')\n",
    "        return id_\n",
    "    except:\n",
    "        pass\n",
    "    return\n",
    "\n",
    "# a = id_song_to_be_scored('cleaned_688~I Wanna Be Loved~Buy This Song.txt')\n",
    "\n",
    "# print('id:', a)\n",
    "\n",
    "\n",
    "def artist_song_to_be_scored(song_to_be_scored):\n",
    "\n",
    "    pattern = re.compile(\n",
    "        r'(cleaned_)(?P<id>[\\d\\D]+)(~)(?P<artist_name>[\\d\\D]+)(~)(?P<song_title>[\\d\\D]+)(.txt)')\n",
    "    match = pattern.match(song_to_be_scored)\n",
    "    try:\n",
    "        artist_ = match.group('artist_name').replace('-', ' ')\n",
    "        return artist_\n",
    "    except:\n",
    "        pass\n",
    "    return\n",
    "\n",
    "# b = artist_song_to_be_scored('cleaned_688~I Wanna Be Loved~Buy This Song.txt')\n",
    "\n",
    "# print('artist:', b)\n",
    "\n",
    "\n",
    "def title_song_to_be_scored(song_to_be_scored):\n",
    "\n",
    "    pattern = re.compile(\n",
    "        r'(cleaned_)(?P<id>[\\d\\D]+)(~)(?P<artist_name>[\\d\\D]+)(~)(?P<song_title>[\\d\\D]+)(.txt)')\n",
    "    match = pattern.match(song_to_be_scored)\n",
    "    try:\n",
    "        song_title_ = match.group('song_title').replace('-', ' ')\n",
    "        return song_title_\n",
    "    except:\n",
    "        pass\n",
    "    return\n",
    "\n",
    "# c = title_song_to_be_scored('cleaned_688~I Wanna Be Loved~Buy This Song.txt')\n",
    "\n",
    "# print('title:', c)\n",
    "\n",
    "def profanity_score_min_max():\n",
    "    #     https://github.com/vzhou842/profanity-check\n",
    "    profanity_score_list_ = []\n",
    "\n",
    "    for artist in set(artists_list()):\n",
    "\n",
    "        for song in artist_s_cleaned_songs_list(artist):\n",
    "            words_of_lyrics = []\n",
    "            raw_text = \"\"\n",
    "            f = open(dir_given + '/Cleaned_Songs/' + song, 'rb')\n",
    "            for line in f.readlines():\n",
    "                this_line_wordlist = line.decode('utf-8').split()\n",
    "                for word in this_line_wordlist:\n",
    "                    words_of_lyrics.append(word)\n",
    "            for word_ in words_of_lyrics:\n",
    "                raw_text += word_+\" \"\n",
    "\n",
    "            song_lyrics_for_profanity_check_ = [raw_text]\n",
    "            profanity_check = predict_prob(song_lyrics_for_profanity_check_)\n",
    "            profanity_score = 1-float(' '.join(map(str, profanity_check)))\n",
    "            profanity_score_list_.append(profanity_score)\n",
    "            f.close()\n",
    "\n",
    "    min_profanity_score_list_ = round(min(profanity_score_list_), 3)\n",
    "    max_profanity_score_list_ = round(max(profanity_score_list_), 3)\n",
    "\n",
    "    return min_profanity_score_list_, max_profanity_score_list_\n",
    "\n",
    "\n",
    "d, e = profanity_score_min_max()\n",
    "\n",
    "print('profanity score: min=', d, ',', 'max=', e)\n",
    "\n",
    "\n",
    "profanity_score_min, profanity_score_max = profanity_score_min_max()\n",
    "\n",
    "\n",
    "def profanity_score(song_to_be_scored):\n",
    "    #     https://github.com/vzhou842/profanity-check\n",
    "    words_of_lyrics_of_song_to_be_scored = []\n",
    "    raw_text = \"\"\n",
    "\n",
    "    f = open(dir_given + '/Cleaned_Songs/' + song_to_be_scored, 'rb')\n",
    "    for line in f.readlines():\n",
    "        this_line_wordlist = line.decode('utf-8').split()\n",
    "        for word in this_line_wordlist:\n",
    "            words_of_lyrics_of_song_to_be_scored.append(word)\n",
    "    for word_ in words_of_lyrics_of_song_to_be_scored:\n",
    "        raw_text += word_+\" \"\n",
    "\n",
    "    song_lyrics_for_profanity_check_of_song_to_be_scored = [raw_text]\n",
    "    profanity_check = predict_prob(\n",
    "        song_lyrics_for_profanity_check_of_song_to_be_scored)\n",
    "    profanity_score_of_song_to_be_scored = 1 - \\\n",
    "        float(' '.join(map(str, profanity_check)))\n",
    "\n",
    "    regularization_step = (profanity_score_of_song_to_be_scored -\n",
    "                           profanity_score_min)/(profanity_score_max - profanity_score_min)\n",
    "    profanity_score_of_song_to_be_scored_regularized = 1 * \\\n",
    "        regularization_step + 0*(1-regularization_step)\n",
    "    f.close()\n",
    "    return round(profanity_score_of_song_to_be_scored_regularized, 1)\n",
    "\n",
    "# f = profanity_score('cleaned_688~I Wanna Be Loved~Buy This Song.txt')\n",
    "\n",
    "# print('profanity score=', f)\n",
    "\n",
    "\n",
    "def love_score_min_max():\n",
    "    love_words_list_ = [\n",
    "        'adore', 'adores', 'adorable', 'affection', 'amour', 'angel', 'bliss',\n",
    "        #                    'care', 'caring', 'chocolate', 'companion', 'compassion', 'concern',\n",
    "        #                    'darling', 'dear', 'desire', 'devotion', 'endearment', 'family',\n",
    "        #                    'fondness', 'forever', 'friendship', 'fun', 'God', 'happiness', 'happy',\n",
    "        'happily', 'heart', 'hugs', 'husband', 'infatuation', 'inspiration',\n",
    "                   'intimacy', 'joy', 'kiss', 'kissed', 'kisses',\n",
    "                   'love', 'loves', 'loved', 'loving',\n",
    "        #                    'loyalty', 'marriage', 'passion', 'relationship', 'romance', 'sex',\n",
    "        #                    'sweet', 'sweetheart', 'tenderness', 'trust', 'warmth', 'wife'\n",
    "    ]\n",
    "    love_score_list_ = []\n",
    "\n",
    "    for artist in set(artists_list()):\n",
    "\n",
    "        for song in artist_s_cleaned_songs_list(artist):\n",
    "            words_of_lyrics = []\n",
    "            f = open(dir_given + '/Cleaned_Songs/' + song, 'rb')\n",
    "            counter_for_love_words = 0\n",
    "            for line in f.readlines():\n",
    "                this_line_wordlist = line.decode('utf-8').split()\n",
    "                for word in this_line_wordlist:\n",
    "                    words_of_lyrics.append(word)\n",
    "\n",
    "            filtered_words = [word for word in words_of_lyrics if word not in stopwords.words(\n",
    "                'english') and len(word) > 1 and word not in ['na', 'la']]  # remove the stopwords\n",
    "            for item in filtered_words:\n",
    "                if item in love_words_list_:\n",
    "                    counter_for_love_words += 1\n",
    "            len_counter_for_love_words = len(love_words_list_)\n",
    "            love_score = counter_for_love_words/len_counter_for_love_words\n",
    "            love_score_rounded = round(love_score, 3)\n",
    "            love_score_list_.append(love_score_rounded)\n",
    "            f.close()\n",
    "\n",
    "    min_love_score_list_ = round(min(love_score_list_), 3)\n",
    "    max_love_score_list_ = round(max(love_score_list_), 3)\n",
    "\n",
    "    return min_love_score_list_, max_love_score_list_\n",
    "\n",
    "# g,h = love_score_min_max()\n",
    "\n",
    "# print('love score: min=', g, ',', 'max=', h)\n",
    "\n",
    "\n",
    "love_score_min, love_score_max = love_score_min_max()\n",
    "\n",
    "\n",
    "def love_score(song_to_be_scored):\n",
    "\n",
    "    love_words_list_ = [\n",
    "        'adore', 'adores', 'adorable', 'affection', 'amour', 'angel', 'bliss',\n",
    "        #                    'care', 'caring', 'chocolate', 'companion', 'compassion', 'concern',\n",
    "        #                    'darling', 'dear', 'desire', 'devotion', 'endearment', 'family',\n",
    "        #                    'fondness', 'forever', 'friendship', 'fun', 'God', 'happiness', 'happy',\n",
    "        'happily', 'heart', 'hugs', 'husband', 'infatuation', 'inspiration',\n",
    "                   'intimacy', 'joy', 'kiss', 'kissed', 'kisses',\n",
    "                   'love', 'loves', 'loved', 'loving',\n",
    "        #                    'loyalty', 'marriage', 'passion', 'relationship', 'romance', 'sex',\n",
    "        #                    'sweet', 'sweetheart', 'tenderness', 'trust', 'warmth', 'wife'\n",
    "    ]\n",
    "    words_of_lyrics_of_song_to_be_scored = []\n",
    "    f = open(dir_given + '/Cleaned_Songs/' + song_to_be_scored, 'rb')\n",
    "    counter_for_love_words = 0\n",
    "    for line in f.readlines():\n",
    "        this_line_wordlist = line.decode('utf-8').split()\n",
    "        for word in this_line_wordlist:\n",
    "            words_of_lyrics_of_song_to_be_scored.append(word)\n",
    "    filtered_words = [word for word in words_of_lyrics_of_song_to_be_scored if word not in stopwords.words(\n",
    "        'english') and len(word) > 1 and word not in ['na', 'la']]  # remove the stopwords\n",
    "    for item in filtered_words:\n",
    "        if item in love_words_list_:\n",
    "            counter_for_love_words += 1\n",
    "    len_counter_for_love_words = len(love_words_list_)\n",
    "    love_score_of_song_to_be_scored = counter_for_love_words/len_counter_for_love_words\n",
    "    love_score_of_song_to_be_scored_rounded = round(\n",
    "        love_score_of_song_to_be_scored, 3)\n",
    "\n",
    "    regularization_step = (love_score_of_song_to_be_scored_rounded -\n",
    "                           love_score_min)/(love_score_max - love_score_min)\n",
    "    love_score_of_song_to_be_scored_rounded_regularized = 1 * \\\n",
    "        regularization_step + 0*(1-regularization_step)\n",
    "    f.close()\n",
    "\n",
    "    return round(love_score_of_song_to_be_scored_rounded_regularized, 1)\n",
    "\n",
    "# i = love_score('cleaned_688~I Wanna Be Loved~Buy This Song.txt')\n",
    "\n",
    "# print('love score=', i)\n",
    "\n",
    "\n",
    "def mood_score_min_max() -> float:\n",
    "    # https://github.com/cjhutto/vaderSentiment\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    mood_score_list_ = []\n",
    "\n",
    "    for artist in set(artists_list()):\n",
    "\n",
    "        for song in artist_s_cleaned_songs_list(artist):\n",
    "            words_of_lyrics = []\n",
    "            raw_text = \"\"\n",
    "            f = open(dir_given + '/Cleaned_Songs/' + song, 'rb')\n",
    "            for line in f.readlines():\n",
    "                this_line_wordlist = line.decode('utf-8').split()\n",
    "                for word in this_line_wordlist:\n",
    "                    words_of_lyrics.append(word)\n",
    "            for word_ in words_of_lyrics:\n",
    "                raw_text += word_+\" \"\n",
    "            mood_score_uncompounded = sid.polarity_scores(raw_text)\n",
    "            mood_score_compounded = mood_score_uncompounded['compound']\n",
    "            mood_score_compounded_rounded = round(mood_score_compounded, 3)\n",
    "            mood_score_list_.append(mood_score_compounded_rounded)\n",
    "            f.close()\n",
    "\n",
    "    min_mood_score_list_ = round(min(mood_score_list_), 3)\n",
    "    max_mood_score_list_ = round(max(mood_score_list_), 3)\n",
    "\n",
    "    return min_mood_score_list_, max_mood_score_list_\n",
    "\n",
    "# j,k = mood_score_min_max()\n",
    "\n",
    "# print('mood score: min=', j, ',', 'max=', k)\n",
    "\n",
    "\n",
    "mood_score_min, mood_score_max = mood_score_min_max()\n",
    "\n",
    "\n",
    "def mood_score(song_to_be_scored) -> float:\n",
    "    # https://github.com/cjhutto/vaderSentiment\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    words_of_lyrics_of_song_to_be_scored = []\n",
    "    raw_text = \"\"\n",
    "\n",
    "    f = open(dir_given + '/Cleaned_Songs/' + song_to_be_scored, 'rb')\n",
    "    for line in f.readlines():\n",
    "        this_line_wordlist = line.decode('utf-8').split()\n",
    "        for word in this_line_wordlist:\n",
    "            words_of_lyrics_of_song_to_be_scored.append(word)\n",
    "    for word_ in words_of_lyrics_of_song_to_be_scored:\n",
    "        raw_text += word_+\" \"\n",
    "    mood_score_uncompounded_of_song_to_be_scored = sid.polarity_scores(\n",
    "        raw_text)\n",
    "    mood_score_compounded_of_song_to_be_scored = mood_score_uncompounded_of_song_to_be_scored[\n",
    "        'compound']\n",
    "    mood_score_compounded_of_song_to_be_scored_rounded = round(\n",
    "        mood_score_compounded_of_song_to_be_scored, 3)\n",
    "\n",
    "    regularization_step = (mood_score_compounded_of_song_to_be_scored_rounded -\n",
    "                           mood_score_min)/(mood_score_max - mood_score_min)\n",
    "    mood_score_compounded_of_song_to_be_scored_rounded_regularized = 1 * \\\n",
    "        regularization_step + 0*(1-regularization_step)\n",
    "    f.close()\n",
    "\n",
    "    return round(mood_score_compounded_of_song_to_be_scored_rounded_regularized, 1)\n",
    "\n",
    "# l = mood_score('cleaned_688~I Wanna Be Loved~Buy This Song.txt')\n",
    "\n",
    "# print('mood score=', l)\n",
    "\n",
    "\n",
    "def length_score_min_max():\n",
    "\n",
    "    length_score_list_ = []\n",
    "\n",
    "    for artist in set(artists_list()):\n",
    "\n",
    "        for song in artist_s_cleaned_songs_list(artist):\n",
    "\n",
    "            num_words = 0\n",
    "\n",
    "            f = open(dir_given + '/Cleaned_Songs/' + song, 'rb')\n",
    "            for line in f.readlines():\n",
    "                this_line_wordlist = line.decode('utf-8').split()\n",
    "                num_words += len(this_line_wordlist)\n",
    "            length_score_list_.append(num_words)\n",
    "            f.close()\n",
    "\n",
    "    min_length_score_list_ = min(length_score_list_)\n",
    "    max_length_score_list_ = max(length_score_list_)\n",
    "\n",
    "    return min_length_score_list_, max_length_score_list_\n",
    "\n",
    "# m,n = length_score_min_max()\n",
    "\n",
    "# print('length score: min=', m, ',', 'max=', n)\n",
    "\n",
    "\n",
    "length_score_min, length_score_max = length_score_min_max()\n",
    "\n",
    "\n",
    "def length_score(song_to_be_scored):\n",
    "\n",
    "    num_words_of_song_to_be_scored = 0\n",
    "    f = open(dir_given + '/Cleaned_Songs/' + song_to_be_scored, 'rb')\n",
    "    for line in f.readlines():\n",
    "        this_line_wordlist = line.decode('utf-8').split()\n",
    "        num_words_of_song_to_be_scored += len(this_line_wordlist)\n",
    "\n",
    "    length_score_of_song_to_be_scored = num_words_of_song_to_be_scored\n",
    "\n",
    "    regularization_step = (length_score_of_song_to_be_scored -\n",
    "                           length_score_min)/(length_score_max - length_score_min)\n",
    "    length_score_of_song_to_be_scored_regularized = 1 * \\\n",
    "        regularization_step + 0*(1-regularization_step)\n",
    "    f.close()\n",
    "\n",
    "    return round(length_score_of_song_to_be_scored_regularized, 1)\n",
    "\n",
    "# o = length_score('cleaned_688~I Wanna Be Loved~Buy This Song.txt')\n",
    "\n",
    "# print('length score=', o)\n",
    "\n",
    "\n",
    "def complexity_score_min_max():\n",
    "\n",
    "    complexity_score_list_ = []\n",
    "\n",
    "    for artist in set(artists_list()):\n",
    "\n",
    "        for song in artist_s_cleaned_songs_list(artist):\n",
    "\n",
    "            num_words = 0\n",
    "            words_of_lyrics = []\n",
    "\n",
    "            f = open(dir_given + '/Cleaned_Songs/' + song, 'rb')\n",
    "            for line in f.readlines():\n",
    "                this_line_wordlist = line.decode('utf-8').split()\n",
    "                num_words += len(this_line_wordlist)\n",
    "                for word_ in this_line_wordlist:\n",
    "                    words_of_lyrics.append(word_)\n",
    "\n",
    "            filtered_words = [word for word in words_of_lyrics if word not in stopwords.words(\n",
    "                'english') and len(word) > 1 and word not in ['na', 'la']]  # remove the stopwords\n",
    "            unique_number_of_words = len(set(filtered_words))\n",
    "            number_of_words = len(words_of_lyrics)\n",
    "            try:\n",
    "                complexity_score = unique_number_of_words/number_of_words\n",
    "                complexity_score = round(complexity_score, 3)\n",
    "                complexity_score_list_.append(complexity_score)\n",
    "            except ZeroDivisionError:\n",
    "                complexity_score = 0\n",
    "                complexity_score = round(complexity_score, 3)\n",
    "                complexity_score_list_.append(complexity_score)\n",
    "                f.close()\n",
    "\n",
    "    min_complexity_score_list_ = min(set(complexity_score_list_))\n",
    "    max_complexity_score_list_ = max(set(complexity_score_list_))\n",
    "\n",
    "    return min_complexity_score_list_, max_complexity_score_list_\n",
    "\n",
    "# p,q = complexity_score_min_max()\n",
    "\n",
    "# print('complexity score: min=', p, ',', 'max=', q)\n",
    "\n",
    "\n",
    "complexity_score_min, complexity_score_max = complexity_score_min_max()\n",
    "\n",
    "\n",
    "def complexity_score(song_to_be_scored):\n",
    "\n",
    "    num_words_of_song_to_be_scored = 0\n",
    "    words_of_lyrics_of_song_to_be_scored = []\n",
    "\n",
    "    f = open(dir_given + '/Cleaned_Songs/' + song_to_be_scored, 'rb')\n",
    "    for line in f.readlines():\n",
    "        this_line_wordlist = line.decode('utf-8').split()\n",
    "        num_words_of_song_to_be_scored += len(this_line_wordlist)\n",
    "        for word_ in this_line_wordlist:\n",
    "            words_of_lyrics_of_song_to_be_scored.append(word_)\n",
    "\n",
    "    filtered_words_of_song_to_be_scored = [word for word in words_of_lyrics_of_song_to_be_scored if word not in stopwords.words(\n",
    "        'english') and len(word) > 1 and word not in ['na', 'la']]  # remove the stopwords\n",
    "    unique_number_of_words_of_song_to_be_scored = len(\n",
    "        set(filtered_words_of_song_to_be_scored))\n",
    "    number_of_words_of_song_to_be_scored = len(\n",
    "        words_of_lyrics_of_song_to_be_scored)\n",
    "    try:\n",
    "        complexity_score_of_song_to_be_scored = unique_number_of_words_of_song_to_be_scored / \\\n",
    "            number_of_words_of_song_to_be_scored\n",
    "        complexity_score_of_song_to_be_scored = round(\n",
    "            complexity_score_of_song_to_be_scored, 3)\n",
    "    except ZeroDivisionError:\n",
    "        complexity_score_of_song_to_be_scored = 0\n",
    "        complexity_score_of_song_to_be_scored = round(\n",
    "            complexity_score_of_song_to_be_scored, 3)\n",
    "    regularization_step = (complexity_score_of_song_to_be_scored -\n",
    "                           complexity_score_min)/(complexity_score_max - complexity_score_min)\n",
    "    complexity_score_of_song_to_be_scored_regularized = 1 * \\\n",
    "        regularization_step + 0*(1-regularization_step)\n",
    "    f.close()\n",
    "\n",
    "    return round(complexity_score_of_song_to_be_scored_regularized, 1)\n",
    "\n",
    "# r = complexity_score('cleaned_688~I Wanna Be Loved~Buy This Song.txt')\n",
    "\n",
    "# print('complexity score=', r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"characterizations:\": [\n",
      "        {\n",
      "            \"id\": \"142\",\n",
      "            \"artist\": \"Snap\",\n",
      "            \"title\": \"Snap\",\n",
      "            \"kids_safe\": 0.9,\n",
      "            \"love\": 0.0,\n",
      "            \"mood\": 0.5,\n",
      "            \"length\": 0.0,\n",
      "            \"complexity\": 0.0\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"498\",\n",
      "            \"artist\": \"Tina Turner\",\n",
      "            \"title\": \"A Fool In Love\",\n",
      "            \"kids_safe\": 0.0,\n",
      "            \"love\": 0.1,\n",
      "            \"mood\": 1.0,\n",
      "            \"length\": 0.3,\n",
      "            \"complexity\": 0.8\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"516\",\n",
      "            \"artist\": \"Patsy Cline\",\n",
      "            \"title\": \"Hungry For Love\",\n",
      "            \"kids_safe\": 0.9,\n",
      "            \"love\": 0.1,\n",
      "            \"mood\": 1.0,\n",
      "            \"length\": 0.2,\n",
      "            \"complexity\": 0.6\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"824\",\n",
      "            \"artist\": \"Nina & Mike\",\n",
      "            \"title\": \"True Love\",\n",
      "            \"kids_safe\": 1.0,\n",
      "            \"love\": 0.2,\n",
      "            \"mood\": 1.0,\n",
      "            \"length\": 0.2,\n",
      "            \"complexity\": 0.4\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"433\",\n",
      "            \"artist\": \"Big Joe Turner\",\n",
      "            \"title\": \"Chains of Love\",\n",
      "            \"kids_safe\": 0.0,\n",
      "            \"love\": 0.1,\n",
      "            \"mood\": 1.0,\n",
      "            \"length\": 0.3,\n",
      "            \"complexity\": 0.6\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"040\",\n",
      "            \"artist\": \"Amy Winehouse\",\n",
      "            \"title\": \"Moody's Mood For Love\",\n",
      "            \"kids_safe\": 0.0,\n",
      "            \"love\": 0.1,\n",
      "            \"mood\": 1.0,\n",
      "            \"length\": 0.7,\n",
      "            \"complexity\": 0.7\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"694\",\n",
      "            \"artist\": \"Brian Piper\",\n",
      "            \"title\": \"There Is No Greater Love\",\n",
      "            \"kids_safe\": 1.0,\n",
      "            \"love\": 0.2,\n",
      "            \"mood\": 1.0,\n",
      "            \"length\": 0.2,\n",
      "            \"complexity\": 0.4\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"836\",\n",
      "            \"artist\": \"Marty Wilde\",\n",
      "            \"title\": \"Teenager In Love\",\n",
      "            \"kids_safe\": 0.9,\n",
      "            \"love\": 0.1,\n",
      "            \"mood\": 0.9,\n",
      "            \"length\": 0.3,\n",
      "            \"complexity\": 0.6\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"777\",\n",
      "            \"artist\": \"Steve Ellis\",\n",
      "            \"title\": \"Everlasting Love\",\n",
      "            \"kids_safe\": 0.9,\n",
      "            \"love\": 0.6,\n",
      "            \"mood\": 1.0,\n",
      "            \"length\": 0.6,\n",
      "            \"complexity\": 0.5\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"662\",\n",
      "            \"artist\": \"Buy This Song\",\n",
      "            \"title\": \"I'm Through with Love\",\n",
      "            \"kids_safe\": 1.0,\n",
      "            \"love\": 0.2,\n",
      "            \"mood\": 1.0,\n",
      "            \"length\": 0.2,\n",
      "            \"complexity\": 0.8\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"747\",\n",
      "            \"artist\": \"Semaj\",\n",
      "            \"title\": \"Step in the Name of Love\",\n",
      "            \"kids_safe\": 0.8,\n",
      "            \"love\": 0.1,\n",
      "            \"mood\": 1.0,\n",
      "            \"length\": 0.1,\n",
      "            \"complexity\": 1.0\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"910\",\n",
      "            \"artist\": \"The Belmonts\",\n",
      "            \"title\": \"A Teenager in Love\",\n",
      "            \"kids_safe\": 0.9,\n",
      "            \"love\": 0.2,\n",
      "            \"mood\": 0.9,\n",
      "            \"length\": 0.4,\n",
      "            \"complexity\": 0.4\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"197\",\n",
      "            \"artist\": \"Slam Stewart\",\n",
      "            \"title\": \"I'm in the Mood for Love\",\n",
      "            \"kids_safe\": 0.3,\n",
      "            \"love\": 0.1,\n",
      "            \"mood\": 1.0,\n",
      "            \"length\": 0.2,\n",
      "            \"complexity\": 0.8\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"361\",\n",
      "            \"artist\": \"Dolly Parton\",\n",
      "            \"title\": \"Puppy Love\",\n",
      "            \"kids_safe\": 0.0,\n",
      "            \"love\": 0.6,\n",
      "            \"mood\": 1.0,\n",
      "            \"length\": 0.3,\n",
      "            \"complexity\": 0.6\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"793\",\n",
      "            \"artist\": \"Leslie Phillips\",\n",
      "            \"title\": \"River of Love\",\n",
      "            \"kids_safe\": 1.0,\n",
      "            \"love\": 0.2,\n",
      "            \"mood\": 0.8,\n",
      "            \"length\": 0.4,\n",
      "            \"complexity\": 0.6\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"981\",\n",
      "            \"artist\": \"The Everly Brothers\",\n",
      "            \"title\": \"Bye Bye Love\",\n",
      "            \"kids_safe\": 0.6,\n",
      "            \"love\": 0.4,\n",
      "            \"mood\": 1.0,\n",
      "            \"length\": 0.3,\n",
      "            \"complexity\": 0.5\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"441\",\n",
      "            \"artist\": \"Eddy Arnold\",\n",
      "            \"title\": \"A Heart Full of Love\",\n",
      "            \"kids_safe\": 1.0,\n",
      "            \"love\": 0.3,\n",
      "            \"mood\": 1.0,\n",
      "            \"length\": 0.3,\n",
      "            \"complexity\": 0.6\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"525\",\n",
      "            \"artist\": \"Rappin' 4 Tay\",\n",
      "            \"title\": \"Sweet Love\",\n",
      "            \"kids_safe\": 0.0,\n",
      "            \"love\": 0.0,\n",
      "            \"mood\": 0.0,\n",
      "            \"length\": 1.0,\n",
      "            \"complexity\": 0.9\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"171\",\n",
      "            \"artist\": \"Kirk Whalum\",\n",
      "            \"title\": \"Any Love\",\n",
      "            \"kids_safe\": 0.8,\n",
      "            \"love\": 0.7,\n",
      "            \"mood\": 1.0,\n",
      "            \"length\": 0.5,\n",
      "            \"complexity\": 0.6\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"1000\",\n",
      "            \"artist\": \"Champian Fulton\",\n",
      "            \"title\": \"Easy to Love\",\n",
      "            \"kids_safe\": 0.8,\n",
      "            \"love\": 0.1,\n",
      "            \"mood\": 1.0,\n",
      "            \"length\": 0.2,\n",
      "            \"complexity\": 0.9\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"657\",\n",
      "            \"artist\": \"Mother's Finest\",\n",
      "            \"title\": \"Baby Love\",\n",
      "            \"kids_safe\": 0.1,\n",
      "            \"love\": 1.0,\n",
      "            \"mood\": 1.0,\n",
      "            \"length\": 0.8,\n",
      "            \"complexity\": 0.3\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"820\",\n",
      "            \"artist\": \"Kenny Drew\",\n",
      "            \"title\": \"There Is No Greater Love\",\n",
      "            \"kids_safe\": 1.0,\n",
      "            \"love\": 0.2,\n",
      "            \"mood\": 1.0,\n",
      "            \"length\": 0.2,\n",
      "            \"complexity\": 0.4\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"767\",\n",
      "            \"artist\": \"Chick Corea\",\n",
      "            \"title\": \"My One and Only Love\",\n",
      "            \"kids_safe\": 1.0,\n",
      "            \"love\": 0.2,\n",
      "            \"mood\": 1.0,\n",
      "            \"length\": 0.2,\n",
      "            \"complexity\": 0.9\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"695\",\n",
      "            \"artist\": \"Scherrie\",\n",
      "            \"title\": \"Baby Love\",\n",
      "            \"kids_safe\": 0.3,\n",
      "            \"love\": 0.6,\n",
      "            \"mood\": 1.0,\n",
      "            \"length\": 0.4,\n",
      "            \"complexity\": 0.6\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"124\",\n",
      "            \"artist\": \"Buck Owens\",\n",
      "            \"title\": \"Down on the Corner of Love\",\n",
      "            \"kids_safe\": 0.2,\n",
      "            \"love\": 0.3,\n",
      "            \"mood\": 1.0,\n",
      "            \"length\": 0.3,\n",
      "            \"complexity\": 0.5\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"757\",\n",
      "            \"artist\": \"Patti Austin\",\n",
      "            \"title\": \"In and Out of Love\",\n",
      "            \"kids_safe\": 1.0,\n",
      "            \"love\": 0.2,\n",
      "            \"mood\": 1.0,\n",
      "            \"length\": 0.4,\n",
      "            \"complexity\": 0.5\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"887\",\n",
      "            \"artist\": \"Gerald Albright\",\n",
      "            \"title\": \"All This Love\",\n",
      "            \"kids_safe\": 0.8,\n",
      "            \"love\": 0.5,\n",
      "            \"mood\": 1.0,\n",
      "            \"length\": 0.4,\n",
      "            \"complexity\": 0.5\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"776\",\n",
      "            \"artist\": \"Deliverance\",\n",
      "            \"title\": \"No Love\",\n",
      "            \"kids_safe\": 0.2,\n",
      "            \"love\": 0.1,\n",
      "            \"mood\": 0.8,\n",
      "            \"length\": 0.2,\n",
      "            \"complexity\": 0.9\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"204\",\n",
      "            \"artist\": \"Michael Mind\",\n",
      "            \"title\": \"Show Me Love\",\n",
      "            \"kids_safe\": 1.0,\n",
      "            \"love\": 0.2,\n",
      "            \"mood\": 1.0,\n",
      "            \"length\": 0.3,\n",
      "            \"complexity\": 0.7\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"502\",\n",
      "            \"artist\": \"Shabba Ranks\",\n",
      "            \"title\": \"Turn It Down\",\n",
      "            \"kids_safe\": 0.6,\n",
      "            \"love\": 0.0,\n",
      "            \"mood\": 1.0,\n",
      "            \"length\": 0.1,\n",
      "            \"complexity\": 0.9\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"112\",\n",
      "            \"artist\": \"Sub Focus\",\n",
      "            \"title\": \"Falling Down\",\n",
      "            \"kids_safe\": 0.9,\n",
      "            \"love\": 0.0,\n",
      "            \"mood\": 0.0,\n",
      "            \"length\": 0.1,\n",
      "            \"complexity\": 0.1\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"108\",\n",
      "            \"artist\": \"Santo & Johnny\",\n",
      "            \"title\": \"Deep Purple\",\n",
      "            \"kids_safe\": 0.9,\n",
      "            \"love\": 0.1,\n",
      "            \"mood\": 1.0,\n",
      "            \"length\": 0.3,\n",
      "            \"complexity\": 0.5\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"443\",\n",
      "            \"artist\": \"Jimmy Giuffre\",\n",
      "            \"title\": \"Deep Purple\",\n",
      "            \"kids_safe\": 0.9,\n",
      "            \"love\": 0.1,\n",
      "            \"mood\": 1.0,\n",
      "            \"length\": 0.3,\n",
      "            \"complexity\": 0.5\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"789\",\n",
      "            \"artist\": \"Alkaline Trio\",\n",
      "            \"title\": \"Hell Yes\",\n",
      "            \"kids_safe\": 0.5,\n",
      "            \"love\": 0.0,\n",
      "            \"mood\": 1.0,\n",
      "            \"length\": 0.5,\n",
      "            \"complexity\": 0.7\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%time\n",
    "# def json_creation(artists_list_, raw_filenames_list_, profanity_score_min, profanity_score_max, love_score_min, love_score_max, mood_score_min, mood_score_max, length_score_min, length_score_max, complexity_score_min, complexity_score_max):\n",
    "dict_for_json = {}\n",
    "for artist in set(artists_list()):   \n",
    "    for song in artist_s_cleaned_songs_list(artist):\n",
    "        dict_for_json_song = {}\n",
    "        dict_for_json_song[\"id\"] = id_song_to_be_scored(song)\n",
    "        dict_for_json_song[\"artist\"] = artist_song_to_be_scored(song)\n",
    "        dict_for_json_song[\"title\"] = title_song_to_be_scored(song)        \n",
    "        dict_for_json_song[\"kids_safe\"] = profanity_score(song)\n",
    "        dict_for_json_song[\"love\"] = love_score(song)\n",
    "        dict_for_json_song[\"mood\"] = mood_score(song)\n",
    "        dict_for_json_song[\"length\"] = length_score(song)\n",
    "        dict_for_json_song[\"complexity\"] = complexity_score(song)\n",
    "\n",
    "#         key, value = 'id', str(id_song_to_be_scored(song))\n",
    "#         if key in dict_for_json and value == dict_for_json[key]:\n",
    "#             print(\"blah\")\n",
    "#         else:\n",
    "        dict_for_json.setdefault('characterizations:', []).append(dict_for_json_song)\n",
    "\n",
    "print(json.dumps(dict_for_json, indent=4, ensure_ascii=False\n",
    "                ))\n",
    "\n",
    "# Checking that all the songs are given a characterization:\n",
    "\n",
    "len(dict_for_json['characterizations:'])\n",
    "\n",
    "#     return\n",
    "\n",
    "# def main():\n",
    "# #    global artists_list_, raw_filenames_list_, profanity_score_min, profanity_score_max, love_score_min, love_score_max, mood_score_min, mood_score_max, length_score_min, length_score_max, complexity_score_min, complexity_score_max\n",
    "#     start_time = time.time()\n",
    "#     artists_list_ = artists_list()\n",
    "#     print(\"Artist Time:\", time.time() - start_time)\n",
    "    \n",
    "#     raw_filenames_list_ = raw_filenames_list()\n",
    "#     song_cleaning()\n",
    "#     print(\"Ceaning Time:\", time.time() - start_time)\n",
    "    \n",
    "#     profanity_score_min, profanity_score_max = profanity_score_min_max()\n",
    "#     love_score_min, love_score_max = love_score_min_max()\n",
    "#     mood_score_min, mood_score_max = mood_score_min_max()\n",
    "#     length_score_min, length_score_max = length_score_min_max()\n",
    "#     complexity_score_min, complexity_score_max = complexity_score_min_max()\n",
    "#     print(\"MinMax Time:\", time.time() - start_time)\n",
    "    \n",
    "#     json_creation(artists_list_, raw_filenames_list_, profanity_score_min, profanity_score_max, love_score_min, love_score_max, mood_score_min, mood_score_max, length_score_min, length_score_max, complexity_score_min, complexity_score_max)\n",
    "#     return\n",
    "# main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "translator = Translator()\n",
    "\n",
    "def song_translating():\n",
    "    for artist in artists_list():\n",
    "        for song in artist_s_songs_list(artist):\n",
    "            words_of_lyrics = []\n",
    "            raw_text = \"\"\n",
    "            if detect(song) == 'en':\n",
    "                pass\n",
    "            else:\n",
    "                f = open(dir_given + '/Cleaned_Songs/cleaned_' + song, 'rb')\n",
    "                for line in f.readlines():\n",
    "                    this_line_wordlist = line.decode('utf-8').split()\n",
    "                    for word in this_line_wordlist:\n",
    "                        if word != ' ':\n",
    "                            words_of_lyrics.append(word)\n",
    "                for word_ in words_of_lyrics:\n",
    "                    translation = translator.translate(word_).text\n",
    "                    raw_text += translation + ' '\n",
    "                print(raw_text)\n",
    "                f.close()\n",
    "                f = open(dir_given + '/Cleaned_Songs/cleaned_' + song, 'wb')\n",
    "                f.write(raw_text.encode('utf-8'))\n",
    "                f.close()       \n",
    "    return\n",
    "\n",
    "song_translating()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator.translate('la puta').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def song_translating():\n",
    "    for artist in artists_list():\n",
    "        for song in artist_s_songs_list(artist):\n",
    "            #Changed below to base on single given directory\n",
    "            f = open(dir_given+ r'/Cleaned_Songs/cleaned_' +  song, 'rb')\n",
    "            all_words = ''\n",
    "            cleaned_songs_directory = dir_given + \"/Cleaned_Songs/\"\n",
    "\n",
    "            for sentence in f.readlines():\n",
    "                this_sentence = sentence.decode('utf-8')\n",
    "                try:\n",
    "                    if translator.detect(this_sentence).lang == 'en':\n",
    "                        all_words += this_sentence\n",
    "                    else:\n",
    "                        print('translating song')\n",
    "                        translation = translator.translate(this_sentence)\n",
    "                        all_words += translation.text\n",
    "                        print('song is translated')\n",
    "                except:\n",
    "                    print('exception')\n",
    "            f = open(cleaned_songs_directory + 'cleaned_' + song, 'wb')\n",
    "            f.write(all_words.encode('utf-8'))\n",
    "            f.close()\n",
    "    return\n",
    "\n",
    "song_translating()\n",
    "\n",
    "# 653~Svefn-G-Englar~Sigur Rós.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(artist_s_songs_list('Sigur Rós'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pipreqs\n",
    "# pipreqs /Users/alexpapaioannou/Downloads/TFA_Project-Kyle\n",
    "\n",
    "\n",
    "# https://pip.pypa.io/en/stable/user_guide/#requirements-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# %%time\n",
    "\n",
    "# parser = argparse.ArgumentParser('Parses the given directory of lyrics')\n",
    "# parser.add_argument('dir_given', help='Directory of the lyrics')\n",
    "# args = parser.parse_args()\n",
    "# dir_given = args.dir_given\n",
    "\n",
    "# Simulated 'Given' directory, needs to be changed to input from command line kss0416\n",
    "\n",
    "dir_given = \\\n",
    "    '/Users/alexpapaioannou/Dropbox/Personal Things/Personal/Studies Related/NY/COLUMBIA UNIVERSITY/IEOR/MSMSE/Courses/IEOR 4501 E 001 TOOLS FOR ANALYTICS/TOOLS_2019/Project_2019/Lyrics'\n",
    "\n",
    "# Need to change path below to start in lyrics directory kss0416\n",
    "\n",
    "os.chdir(dir_given)\n",
    "\n",
    "\n",
    "def artists_list():\n",
    "    artists_list_ = []\n",
    "    for raw_filename in os.listdir(dir_given):\n",
    "        if raw_filename.endswith('.txt'):\n",
    "            try:\n",
    "                artist_name = raw_filename.split('~')[2].split('.txt'\n",
    "                                                               )[0]\n",
    "                if artist_name not in artists_list_:\n",
    "                    artists_list_.append(artist_name)\n",
    "            except IndexError:\n",
    "                pass\n",
    "    return artists_list_\n",
    "\n",
    "\n",
    "def raw_filenames_list():\n",
    "    raw_filenames_list_ = []\n",
    "    for raw_filename in os.listdir(dir_given):\n",
    "        if raw_filename.endswith('.txt'):\n",
    "            raw_filenames_list_.append(raw_filename)\n",
    "    return raw_filenames_list_\n",
    "\n",
    "\n",
    "def artist_s_songs_list(str):\n",
    "    artist_s_songs_list_ = []\n",
    "    for raw_filename in raw_filenames_list():\n",
    "        if raw_filename.endswith(str + '.txt'):\n",
    "            artist_s_songs_list_.append(raw_filename)\n",
    "    return artist_s_songs_list_\n",
    "\n",
    "\n",
    "def artist_s_cleaned_songs_list(str):\n",
    "    artist_s_cleaned_songs_list_ = []\n",
    "    for cleaned_raw_filename in os.listdir(dir_given + '/Cleaned_Songs/'\n",
    "                                           ):\n",
    "        if cleaned_raw_filename.endswith(str + '.txt') is True:\n",
    "            if cleaned_raw_filename.endswith(str + '.txt') \\\n",
    "                    not in artist_s_cleaned_songs_list_:\n",
    "                artist_s_cleaned_songs_list_.append(cleaned_raw_filename)\n",
    "    return artist_s_cleaned_songs_list_\n",
    "\n",
    "\n",
    "artist_s_cleaned_songs_list('The Beatles')\n",
    "\n",
    "\n",
    "def song_cleaning():\n",
    "    for artist in artists_list():\n",
    "        for song in artist_s_songs_list(artist):\n",
    "            f = open('Lyrics/' + song, 'rb')\n",
    "            all_words = ''\n",
    "            for sentence in f.readlines():\n",
    "                this_sentence = sentence.decode('utf-8')\n",
    "                all_words += this_sentence\n",
    "\n",
    "            # remove identifiers like chorus, verse, etc\n",
    "\n",
    "            all_words = re.sub(r'[\\(\\[],.*?[\\)\\]]', '', all_words)\n",
    "\n",
    "            # remove empty lines\n",
    "\n",
    "            all_words = os.linesep.join([s for s in\n",
    "                                         all_words.splitlines() if s])\n",
    "            f.close()\n",
    "            directory = 'Lyrics/Cleaned_Songs'\n",
    "            f = open(os.path.join(directory, 'cleaned_' + song), 'wb')\n",
    "            f.write(all_words.encode('utf-8'))\n",
    "            f.close()\n",
    "    return\n",
    "\n",
    "\n",
    "# def song_translating(artists_list):\n",
    "#     cleaned_songs_directory = dir_given + \"/Cleaned_Songs/\"\n",
    "#     for artist in artists_list:\n",
    "#         for song in artist_s_songs_list(artist):\n",
    "#             try:\n",
    "#                 if translator.detect(this_sentence).lang == 'en':\n",
    "#                     pass\n",
    "#                 else:\n",
    "#                     f = open(cleaned_songs_directory + 'cleaned_' + song, 'rb')\n",
    "#                     all_words = ''\n",
    "#                     for sentence in f.readlines():\n",
    "#                         this_sentence = sentence.decode('utf-8')\n",
    "#                         translation = translator.translate(this_sentence)\n",
    "#                         all_words += translation.text\n",
    "#                     print(song)\n",
    "#                     print(all_words)\n",
    "#                     f.write(all_words.encode('utf-8'))\n",
    "#                     f.close()\n",
    "#             except:\n",
    "#                 print('exception')\n",
    "#     return\n",
    "\n",
    "# song_translating(artists_list())\n",
    "\n",
    "# def song_translating(artists_list):\n",
    "#     for artist in set(artists_list):\n",
    "#         for song in artist_s_songs_list(artist):\n",
    "#             #Changed below to base on single given directory\n",
    "#             f = open(dir_given + r'/Cleaned_Songs/cleaned_' +  song, 'rb')\n",
    "#             all_words = ''\n",
    "#             cleaned_songs_directory = dir_given + \"/Cleaned_Songs/\"\n",
    "\n",
    "#             for sentence in f.readlines():\n",
    "#                 this_sentence = sentence.decode('utf-8')\n",
    "#                 try:\n",
    "#                     if translator.detect(this_sentence).lang == 'en':\n",
    "#                         all_words += this_sentence\n",
    "#                     else:\n",
    "#                         translation = translator.translate(this_sentence)\n",
    "#                         all_words += translation.text\n",
    "#                 except:\n",
    "#                     print('exception')\n",
    "#             f = open(cleaned_songs_directory + 'cleaned_' + song, 'wb')\n",
    "#             f.write(all_words.encode('utf-8'))\n",
    "#             f.close()\n",
    "#     return\n",
    "\n",
    "# song_translating(artists_list())\n",
    "\n",
    "def id_song_to_be_scored(song_to_be_scored):\n",
    "\n",
    "    pattern = re.compile(r'(cleaned_)(\\d+)(~)(\\D+)(~)(\\D+)(.txt)')\n",
    "    match = pattern.match(song_to_be_scored)\n",
    "    if match is True:\n",
    "        try:\n",
    "            id_ = match.group(2)\n",
    "            return id_\n",
    "        except:\n",
    "            pass\n",
    "    else:\n",
    "        pattern = re.compile(r'(\\d+)(~)(\\D+)(~)(\\D+)(.txt)')\n",
    "        match = pattern.match(song_to_be_scored)\n",
    "        try:\n",
    "            id_ = match.group(1)\n",
    "            return id_\n",
    "        except:\n",
    "            pass\n",
    "    return\n",
    "\n",
    "\n",
    "# a = id_song_to_be_scored('cleaned_688~I Wanna Be Loved~Buy This Song.txt')\n",
    "\n",
    "# print('id:', a)\n",
    "\n",
    "def artist_song_to_be_scored(song_to_be_scored):\n",
    "\n",
    "    pattern = re.compile(r'(cleaned_)(\\d+)(~)(\\D+)(~)(\\D+)(.txt)')\n",
    "    match = pattern.match(song_to_be_scored)\n",
    "    if match is True:\n",
    "        try:\n",
    "            artist_ = match.group(6)\n",
    "            return artist_\n",
    "        except:\n",
    "            pass\n",
    "    else:\n",
    "        pattern = re.compile(r'(\\d+)(~)(\\D+)(~)(\\D+)(.txt)')\n",
    "        match = pattern.match(song_to_be_scored)\n",
    "        try:\n",
    "            artist_ = match.group(5)\n",
    "            return artist_\n",
    "        except:\n",
    "            pass\n",
    "    return\n",
    "\n",
    "\n",
    "# b = artist_song_to_be_scored('cleaned_688~I Wanna Be Loved~Buy This Song.txt')\n",
    "\n",
    "# print('artist:', b)\n",
    "\n",
    "def title_song_to_be_scored(song_to_be_scored):\n",
    "\n",
    "    pattern = re.compile(r'(cleaned_)(\\d+)(~)(\\D+)(~)(\\D+)(.txt)')\n",
    "    match = pattern.match(song_to_be_scored)\n",
    "    if match is True:\n",
    "        try:\n",
    "            song_title_ = match.group(4)\n",
    "            return song_title_\n",
    "        except:\n",
    "            pass\n",
    "    else:\n",
    "        pattern = re.compile(r'(\\d+)(~)(\\D+)(~)(\\D+)(.txt)')\n",
    "        match = pattern.match(song_to_be_scored)\n",
    "        try:\n",
    "            song_title_ = match.group(3)\n",
    "            return song_title_\n",
    "        except:\n",
    "            pass\n",
    "    return\n",
    "\n",
    "\n",
    "# c = title_song_to_be_scored('cleaned_688~I Wanna Be Loved~Buy This Song.txt')\n",
    "\n",
    "# print('title:', c)\n",
    "\n",
    "def profanity_score_min_max():\n",
    "\n",
    "    #     https://github.com/vzhou842/profanity-check\n",
    "\n",
    "    profanity_score_list_ = []\n",
    "\n",
    "    for artist in artists_list():\n",
    "\n",
    "        for song in artist_s_cleaned_songs_list(artist):\n",
    "            words_of_lyrics = []\n",
    "            raw_text = ''\n",
    "            f = open(dir_given + '/Cleaned_Songs/' + song, 'rb')\n",
    "            for line in f.readlines():\n",
    "                this_line_wordlist = line.decode('utf-8').split()\n",
    "                for word in this_line_wordlist:\n",
    "                    words_of_lyrics.append(word)\n",
    "            f.close()\n",
    "            for word_ in words_of_lyrics:\n",
    "                raw_text += word_ + ' '\n",
    "\n",
    "            song_lyrics_for_profanity_check_ = [raw_text]\n",
    "            profanity_check = \\\n",
    "                predict_prob(song_lyrics_for_profanity_check_)\n",
    "            profanity_score = 1 - float(' '.join(map(str,\n",
    "                                                     profanity_check)))\n",
    "            profanity_score_list_.append(profanity_score)\n",
    "\n",
    "    min_profanity_score_list_ = round(min(profanity_score_list_), 2)\n",
    "    max_profanity_score_list_ = round(max(profanity_score_list_), 2)\n",
    "\n",
    "    return (min_profanity_score_list_, max_profanity_score_list_)\n",
    "\n",
    "\n",
    "# d,e = profanity_score_min_max()\n",
    "\n",
    "# print('profanity score: min=', d, ',', 'max=', e)\n",
    "\n",
    "(profanity_score_min, profanity_score_max) = profanity_score_min_max()\n",
    "\n",
    "\n",
    "def profanity_score(song_to_be_scored):\n",
    "\n",
    "    #     https://github.com/vzhou842/profanity-check\n",
    "\n",
    "    words_of_lyrics_of_song_to_be_scored = []\n",
    "    raw_text = ''\n",
    "\n",
    "    f = open(dir_given + '/Cleaned_Songs/' + song_to_be_scored, 'rb')\n",
    "    for line in f.readlines():\n",
    "        this_line_wordlist = line.decode('utf-8').split()\n",
    "        for word in this_line_wordlist:\n",
    "            words_of_lyrics_of_song_to_be_scored.append(word)\n",
    "    f.close()\n",
    "    for word_ in words_of_lyrics_of_song_to_be_scored:\n",
    "        raw_text += word_ + ' '\n",
    "\n",
    "    song_lyrics_for_profanity_check_of_song_to_be_scored = [raw_text]\n",
    "    profanity_check = \\\n",
    "        predict_prob(song_lyrics_for_profanity_check_of_song_to_be_scored)\n",
    "    profanity_score_of_song_to_be_scored = 1 - float(' '.join(map(str,\n",
    "                                                                  profanity_check)))\n",
    "\n",
    "    regularization_step = (profanity_score_of_song_to_be_scored\n",
    "                           - profanity_score_min) \\\n",
    "        / (profanity_score_max - profanity_score_min)\n",
    "    profanity_score_of_song_to_be_scored_regularized = 1 \\\n",
    "        * regularization_step + 0 * (1 - regularization_step)\n",
    "\n",
    "    return round(profanity_score_of_song_to_be_scored_regularized, 4)\n",
    "\n",
    "\n",
    "# f = profanity_score('cleaned_688~I Wanna Be Loved~Buy This Song.txt')\n",
    "\n",
    "# print('profanity score=', f)\n",
    "\n",
    "def love_score_min_max():\n",
    "    love_words_list_ = [  # 'care', 'caring', 'chocolate', 'companion', 'compassion', 'concern',\n",
    "                          #                    'darling', 'dear', 'desire', 'devotion', 'endearment', 'family',\n",
    "                          #                    'fondness', 'forever', 'friendship', 'fun', 'God', 'happiness', 'happy',\n",
    "        'adore',\n",
    "        'adores',\n",
    "        'adorable',\n",
    "        'affection',\n",
    "        'amour',\n",
    "        'angel',\n",
    "        'bliss',\n",
    "        'happily',\n",
    "        'heart',\n",
    "        'hugs',\n",
    "        'husband',\n",
    "        'infatuation',\n",
    "        'inspiration',\n",
    "        'intimacy',\n",
    "        'joy',\n",
    "        'kiss',\n",
    "        'kissed',\n",
    "        'kisses',\n",
    "        'love',\n",
    "        'loves',\n",
    "        'loved',\n",
    "        'loving',\n",
    "    ]\n",
    "\n",
    "#                    'loyalty', 'marriage', 'passion', 'relationship', 'romance', 'sex',\n",
    "#                    'sweet', 'sweetheart', 'tenderness', 'trust', 'warmth', 'wife'\n",
    "\n",
    "    love_score_list_ = []\n",
    "\n",
    "    for artist in artists_list():\n",
    "\n",
    "        for song in artist_s_cleaned_songs_list(artist):\n",
    "            words_of_lyrics = []\n",
    "            f = open(dir_given + '/Cleaned_Songs/' + song, 'rb')\n",
    "            counter_for_love_words = 0\n",
    "            for line in f.readlines():\n",
    "                this_line_wordlist = line.decode('utf-8').split()\n",
    "                for word in this_line_wordlist:\n",
    "                    words_of_lyrics.append(word)\n",
    "            f.close()\n",
    "\n",
    "            filtered_words = [word for word in words_of_lyrics if word\n",
    "                              not in stopwords.words('english')\n",
    "                              and len(word) > 1 and word not in ['na',\n",
    "                                                                 'la']]  # remove the stopwords\n",
    "            for item in filtered_words:\n",
    "                if item in love_words_list_:\n",
    "                    counter_for_love_words += 1\n",
    "            len_counter_for_love_words = len(love_words_list_)\n",
    "            love_score = counter_for_love_words \\\n",
    "                / len_counter_for_love_words\n",
    "            love_score_rounded = round(love_score, 4)\n",
    "            love_score_list_.append(love_score_rounded)\n",
    "\n",
    "    min_love_score_list_ = round(min(love_score_list_), 4)\n",
    "    max_love_score_list_ = round(max(love_score_list_), 4)\n",
    "\n",
    "    return (min_love_score_list_, max_love_score_list_)\n",
    "\n",
    "\n",
    "# g,h = love_score_min_max()\n",
    "\n",
    "# print('love score: min=', g, ',', 'max=', h)\n",
    "\n",
    "(love_score_min, love_score_max) = love_score_min_max()\n",
    "\n",
    "\n",
    "def love_score(song_to_be_scored):\n",
    "\n",
    "    love_words_list_ = [  # 'care', 'caring', 'chocolate', 'companion', 'compassion', 'concern',\n",
    "                          #                    'darling', 'dear', 'desire', 'devotion', 'endearment', 'family',\n",
    "                          #                    'fondness', 'forever', 'friendship', 'fun', 'God', 'happiness', 'happy',\n",
    "        'adore',\n",
    "        'adores',\n",
    "        'adorable',\n",
    "        'affection',\n",
    "        'amour',\n",
    "        'angel',\n",
    "        'bliss',\n",
    "        'happily',\n",
    "        'heart',\n",
    "        'hugs',\n",
    "        'husband',\n",
    "        'infatuation',\n",
    "        'inspiration',\n",
    "        'intimacy',\n",
    "        'joy',\n",
    "        'kiss',\n",
    "        'kissed',\n",
    "        'kisses',\n",
    "        'love',\n",
    "        'loves',\n",
    "        'loved',\n",
    "        'loving',\n",
    "    ]\n",
    "\n",
    "#                    'loyalty', 'marriage', 'passion', 'relationship', 'romance', 'sex',\n",
    "#                    'sweet', 'sweetheart', 'tenderness', 'trust', 'warmth', 'wife'\n",
    "\n",
    "    words_of_lyrics_of_song_to_be_scored = []\n",
    "    f = open(dir_given + '/Cleaned_Songs/' + song_to_be_scored, 'rb')\n",
    "    counter_for_love_words = 0\n",
    "    for line in f.readlines():\n",
    "        this_line_wordlist = line.decode('utf-8').split()\n",
    "        for word in this_line_wordlist:\n",
    "            words_of_lyrics_of_song_to_be_scored.append(word)\n",
    "    filtered_words = [word for word in\n",
    "                      words_of_lyrics_of_song_to_be_scored if word\n",
    "                      not in stopwords.words('english') and len(word)\n",
    "                      > 1 and word not in ['na', 'la']]  # remove the stopwords\n",
    "    for item in filtered_words:\n",
    "        if item in love_words_list_:\n",
    "            counter_for_love_words += 1\n",
    "    len_counter_for_love_words = len(love_words_list_)\n",
    "    love_score_of_song_to_be_scored = counter_for_love_words \\\n",
    "        / len_counter_for_love_words\n",
    "    love_score_of_song_to_be_scored_rounded = \\\n",
    "        round(love_score_of_song_to_be_scored, 4)\n",
    "\n",
    "    regularization_step = (love_score_of_song_to_be_scored_rounded\n",
    "                           - love_score_min) / (love_score_max\n",
    "                                                - love_score_min)\n",
    "    love_score_of_song_to_be_scored_rounded_regularized = 1 \\\n",
    "        * regularization_step + 0 * (1 - regularization_step)\n",
    "\n",
    "    return round(love_score_of_song_to_be_scored_rounded_regularized, 4)\n",
    "\n",
    "\n",
    "# i = love_score('cleaned_688~I Wanna Be Loved~Buy This Song.txt')\n",
    "\n",
    "# print('love score=', i)\n",
    "\n",
    "def mood_score_min_max():\n",
    "\n",
    "    # https://github.com/cjhutto/vaderSentiment\n",
    "\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    mood_score_list_ = []\n",
    "\n",
    "    for artist in artists_list():\n",
    "\n",
    "        for song in artist_s_cleaned_songs_list(artist):\n",
    "            words_of_lyrics = []\n",
    "            raw_text = ''\n",
    "            f = open(dir_given + '/Cleaned_Songs/' + song, 'rb')\n",
    "            for line in f.readlines():\n",
    "                this_line_wordlist = line.decode('utf-8').split()\n",
    "                for word in this_line_wordlist:\n",
    "                    words_of_lyrics.append(word)\n",
    "            for word_ in words_of_lyrics:\n",
    "                raw_text += word_ + ' '\n",
    "            mood_score_uncompounded = sid.polarity_scores(raw_text)\n",
    "            mood_score_compounded = mood_score_uncompounded['compound']\n",
    "            mood_score_compounded_rounded = \\\n",
    "                round(mood_score_compounded, 2)\n",
    "            mood_score_list_.append(mood_score_compounded_rounded)\n",
    "\n",
    "    min_mood_score_list_ = round(min(mood_score_list_), 4)\n",
    "    max_mood_score_list_ = round(max(mood_score_list_), 4)\n",
    "\n",
    "    return (min_mood_score_list_, max_mood_score_list_)\n",
    "\n",
    "\n",
    "# j,k = mood_score_min_max()\n",
    "\n",
    "# print('mood score: min=', j, ',', 'max=', k)\n",
    "\n",
    "(mood_score_min, mood_score_max) = mood_score_min_max()\n",
    "\n",
    "\n",
    "def mood_score(song_to_be_scored):\n",
    "\n",
    "    # https://github.com/cjhutto/vaderSentiment\n",
    "\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    words_of_lyrics_of_song_to_be_scored = []\n",
    "    raw_text = ''\n",
    "\n",
    "    f = open(dir_given + '/Cleaned_Songs/' + song_to_be_scored, 'rb')\n",
    "    for line in f.readlines():\n",
    "        this_line_wordlist = line.decode('utf-8').split()\n",
    "        for word in this_line_wordlist:\n",
    "            words_of_lyrics_of_song_to_be_scored.append(word)\n",
    "    for word_ in words_of_lyrics_of_song_to_be_scored:\n",
    "        raw_text += word_ + ' '\n",
    "    mood_score_uncompounded_of_song_to_be_scored = \\\n",
    "        sid.polarity_scores(raw_text)\n",
    "    mood_score_compounded_of_song_to_be_scored = \\\n",
    "        mood_score_uncompounded_of_song_to_be_scored['compound']\n",
    "    mood_score_compounded_of_song_to_be_scored_rounded = \\\n",
    "        round(mood_score_compounded_of_song_to_be_scored, 2)\n",
    "\n",
    "    regularization_step = \\\n",
    "        (mood_score_compounded_of_song_to_be_scored_rounded\n",
    "         - mood_score_min) / (mood_score_max - mood_score_min)\n",
    "    mood_score_compounded_of_song_to_be_scored_rounded_regularized = 1 \\\n",
    "        * regularization_step + 0 * (1 - regularization_step)\n",
    "\n",
    "    return round(mood_score_compounded_of_song_to_be_scored_rounded_regularized,\n",
    "                 4)\n",
    "\n",
    "\n",
    "# l = mood_score('cleaned_688~I Wanna Be Loved~Buy This Song.txt')\n",
    "\n",
    "# print('mood score=', l)\n",
    "\n",
    "def length_score_min_max():\n",
    "\n",
    "    length_score_list_ = []\n",
    "\n",
    "    for artist in artists_list():\n",
    "\n",
    "        for song in artist_s_cleaned_songs_list(artist):\n",
    "\n",
    "            num_words = 0\n",
    "\n",
    "            f = open(dir_given + '/Cleaned_Songs/' + song, 'rb')\n",
    "            for line in f.readlines():\n",
    "                this_line_wordlist = line.decode('utf-8').split()\n",
    "                num_words += len(this_line_wordlist)\n",
    "            length_score_list_.append(num_words)\n",
    "\n",
    "    min_length_score_list_ = min(length_score_list_)\n",
    "    max_length_score_list_ = max(length_score_list_)\n",
    "\n",
    "    return (min_length_score_list_, max_length_score_list_)\n",
    "\n",
    "\n",
    "# m,n = length_score_min_max()\n",
    "\n",
    "# print('length score: min=', m, ',', 'max=', n)\n",
    "\n",
    "(length_score_min, length_score_max) = length_score_min_max()\n",
    "\n",
    "\n",
    "def length_score(song_to_be_scored):\n",
    "\n",
    "    num_words_of_song_to_be_scored = 0\n",
    "    f = open(dir_given + '/Cleaned_Songs/' + song_to_be_scored, 'rb')\n",
    "    for line in f.readlines():\n",
    "        this_line_wordlist = line.decode('utf-8').split()\n",
    "        num_words_of_song_to_be_scored += len(this_line_wordlist)\n",
    "\n",
    "    length_score_of_song_to_be_scored = num_words_of_song_to_be_scored\n",
    "\n",
    "    regularization_step = (length_score_of_song_to_be_scored\n",
    "                           - length_score_min) / (length_score_max\n",
    "                                                  - length_score_min)\n",
    "    length_score_of_song_to_be_scored_regularized = 1 \\\n",
    "        * regularization_step + 0 * (1 - regularization_step)\n",
    "\n",
    "    return round(length_score_of_song_to_be_scored_regularized, 2)\n",
    "\n",
    "\n",
    "# o = length_score('cleaned_688~I Wanna Be Loved~Buy This Song.txt')\n",
    "\n",
    "# print('length score=', o)\n",
    "\n",
    "def complexity_score_min_max():\n",
    "\n",
    "    complexity_score_list_ = []\n",
    "\n",
    "    for artist in artists_list():\n",
    "\n",
    "        for song in artist_s_cleaned_songs_list(artist):\n",
    "\n",
    "            num_words = 0\n",
    "            words_of_lyrics = []\n",
    "\n",
    "            f = open(dir_given() + '/Cleaned_Songs/' + song, 'rb')\n",
    "            for line in f.readlines():\n",
    "                this_line_wordlist = line.decode('utf-8').split()\n",
    "                num_words += len(this_line_wordlist)\n",
    "                for word_ in this_line_wordlist:\n",
    "                    words_of_lyrics.append(word_)\n",
    "\n",
    "            filtered_words = [word for word in words_of_lyrics if word\n",
    "                              not in stopwords.words('english')\n",
    "                              and len(word) > 1 and word not in ['na',\n",
    "                                                                 'la']]  # remove the stopwords\n",
    "            unique_number_of_words = len(set(filtered_words))\n",
    "            number_of_words = len(words_of_lyrics)\n",
    "            try:\n",
    "                complexity_score = unique_number_of_words \\\n",
    "                    / number_of_words\n",
    "                complexity_score = round(complexity_score, 2)\n",
    "                complexity_score_list_.append(complexity_score)\n",
    "            except ZeroDivisionError:\n",
    "                complexity_score = 0\n",
    "                complexity_score = round(complexity_score, 2)\n",
    "                complexity_score_list_.append(complexity_score)\n",
    "\n",
    "    min_complexity_score_list_ = min(set(complexity_score_list_))\n",
    "    max_complexity_score_list_ = max(set(complexity_score_list_))\n",
    "\n",
    "    return (min_complexity_score_list_, max_complexity_score_list_)\n",
    "\n",
    "\n",
    "# p,q = complexity_score_min_max()\n",
    "\n",
    "# print('complexity score: min=', p, ',', 'max=', q)\n",
    "\n",
    "(complexity_score_min, complexity_score_max) = \\\n",
    "    complexity_score_min_max()\n",
    "\n",
    "\n",
    "def complexity_score(song_to_be_scored):\n",
    "\n",
    "    num_words_of_song_to_be_scored = 0\n",
    "    words_of_lyrics_of_song_to_be_scored = []\n",
    "\n",
    "    f = open(dir_given() + '/Cleaned_Songs/' + song_to_be_scored, 'rb')\n",
    "    for line in f.readlines():\n",
    "        this_line_wordlist = line.decode('utf-8').split()\n",
    "        num_words_of_song_to_be_scored += len(this_line_wordlist)\n",
    "        for word_ in this_line_wordlist:\n",
    "            words_of_lyrics_of_song_to_be_scored.append(word_)\n",
    "\n",
    "    filtered_words_of_song_to_be_scored = [word for word in\n",
    "                                           words_of_lyrics_of_song_to_be_scored if word\n",
    "                                           not in stopwords.words('english') and len(word) > 1\n",
    "                                           and word not in ['na', 'la']]  # remove the stopwords\n",
    "    unique_number_of_words_of_song_to_be_scored = \\\n",
    "        len(set(filtered_words_of_song_to_be_scored))\n",
    "    number_of_words_of_song_to_be_scored = \\\n",
    "        len(words_of_lyrics_of_song_to_be_scored)\n",
    "    complexity_score_of_song_to_be_scored = \\\n",
    "        unique_number_of_words_of_song_to_be_scored \\\n",
    "        / number_of_words_of_song_to_be_scored\n",
    "    complexity_score_of_song_to_be_scored = \\\n",
    "        round(complexity_score_of_song_to_be_scored, 2)\n",
    "\n",
    "    regularization_step = (complexity_score_of_song_to_be_scored\n",
    "                           - complexity_score_min) \\\n",
    "        / (complexity_score_max - complexity_score_min)\n",
    "    complexity_score_of_song_to_be_scored_regularized = 1 \\\n",
    "        * regularization_step + 0 * (1 - regularization_step)\n",
    "\n",
    "    return round(complexity_score_of_song_to_be_scored_regularized, 2)\n",
    "\n",
    "\n",
    "# r = complexity_score('cleaned_688~I Wanna Be Loved~Buy This Song.txt')\n",
    "\n",
    "# print('complexity score=', r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get Back\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The Beatles'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(title_song_to_be_scored('cleaned_860~The Beatles~Get Back.txt'))\n",
    "print(artist_s_songs_list('The Beatles'))\n",
    "\n",
    "'860~The Beatles~Get Back.txt'.split(\"~\")[1].split(\"~\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "Downloads/TFA_Project-Kyle/Main_Notebook_4th_version.ipynb",
    "public": true
   },
   "id": ""
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": false,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
