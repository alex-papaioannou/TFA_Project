{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kyle_Shipley\\Anaconda3\\lib\\site-packages\\nltk\\twitter\\__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting profanity-check\n",
      "  Using cached https://files.pythonhosted.org/packages/ff/f8/8073dd1939ee3d2ee9da977599380f30923289f477e90cacc2f0d9af286b/profanity_check-1.0.2-py3-none-any.whl\n",
      "Collecting scikit-learn==0.20.2 (from profanity-check)\n",
      "  Using cached https://files.pythonhosted.org/packages/d1/6c/6ddb21e203ff95d7080aeee2105b4f6610a02483e00d4ac950f3630969c9/scikit_learn-0.20.2-cp37-cp37m-win_amd64.whl\n",
      "Requirement already satisfied: numpy>=1.8.2 in c:\\users\\kyle_shipley\\anaconda3\\lib\\site-packages (from scikit-learn==0.20.2->profanity-check) (1.15.4)\n",
      "Requirement already satisfied: scipy>=0.13.3 in c:\\users\\kyle_shipley\\anaconda3\\lib\\site-packages (from scikit-learn==0.20.2->profanity-check) (1.1.0)\n",
      "Installing collected packages: scikit-learn, profanity-check\n",
      "Successfully installed profanity-check-1.0.2 scikit-learn-0.20.2\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "#environment setting\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import re\n",
    "# Library Import and Environment Setting needed for Logistic Regression\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rc(\"font\", size=16)\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "import glob\n",
    "import re\n",
    "\n",
    "import json\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk.data\n",
    "nltk.downloader.download('vader_lexicon')\n",
    "nltk.downloader.download('stopwords')\n",
    "\n",
    "# from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "!pip install profanity-check\n",
    "from profanity_check import predict, predict_prob\n",
    "# https://github.com/vzhou842/profanity-check\n",
    "\n",
    "!pip install filelock --ignore-installed\n",
    "\n",
    "import argparse\n",
    "\n",
    "!pip install coverage --ignore-installed\n",
    "!pip install langdetect\n",
    "from langdetect import detect\n",
    "\n",
    "!pip install googletrans\n",
    "from googletrans import Translator\n",
    "translator = Translator()\n",
    "\n",
    "import unittest\n",
    "\n",
    "# !pip install py-translator\n",
    "# from py_translator import Translator\n",
    "\n",
    "# !pip install translate\n",
    "\n",
    "# from translate import Translator\n",
    "# translator = Translator(to_lang='en')\n",
    "\n",
    "import requests, uuid\n",
    "\n",
    "# import goslate\n",
    "\n",
    "# imports()\n",
    "\n",
    "# import_time = time.time()\n",
    "# print(import_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '222~All This Time Still Falling out of Love [Album Version]~Erasure.txt'.split(\".txt\")[0]\n",
    "\n",
    "#kss2170 05/04/19 changes:\n",
    "#Output of id of songs is not integers\n",
    "#Unittesting implemented\n",
    "#Merged all function calls into a main() function\n",
    "#JSON Outputting 1007 elements, need to find out why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# cell_s_t = time.time()\n",
    "    \n",
    "#     parser = argparse.ArgumentParser('Parses the given directory of lyrics')\n",
    "#     parser.add_argument('dir_given', help='Directory of the lyrics')\n",
    "#     args = parser.parse_args()\n",
    "#     dir_given = args.dir_given\n",
    "\n",
    "#Simulated 'Given' directory, needs to be changed to input from command line kss0416\n",
    "# dir_given = r'C:\\Users\\Kyle_Shipley\\Documents\\Columbia_Docs\\IEOR 4501\\ProjectTemp\\TFA_Project-Alex2\\TFA_Project-Alex\\Lyrics'\n",
    "\n",
    "#Need to change path below to start in lyrics directory kss0416\n",
    "# os.chdir(dir_given)\n",
    "\n",
    "def artists_list()->list:\n",
    "    artists_list_ = []\n",
    "    for raw_filename in os.listdir(dir_given):\n",
    "        if raw_filename.endswith('.txt'):\n",
    "            try:\n",
    "                artist_name = raw_filename.split(\"~\")[2].split(\".txt\")[0]\n",
    "                if artist_name not in artists_list_:\n",
    "                    artists_list_.append(artist_name)\n",
    "            except IndexError:\n",
    "                pass\n",
    "    return artists_list_\n",
    "\n",
    "# artists_list_ = artists_list()\n",
    "\n",
    "def raw_filenames_list()->list:\n",
    "    raw_filenames_list_ = []\n",
    "    for raw_filename in os.listdir(dir_given):\n",
    "        if raw_filename.endswith('.txt'):\n",
    "            raw_filenames_list_.append(raw_filename)\n",
    "    return raw_filenames_list_\n",
    "\n",
    "# raw_filenames_list_ = raw_filenames_list()\n",
    "\n",
    "def artist_s_songs_list(str)->list:\n",
    "    artist_s_songs_list_ = []\n",
    "    for raw_filename in raw_filenames_list_:\n",
    "        if raw_filename.endswith(str+'.txt'):\n",
    "            artist_s_songs_list_.append(raw_filename)\n",
    "    return artist_s_songs_list_\n",
    "\n",
    "def song_cleaning():\n",
    "    try:\n",
    "        os.mkdir(dir_given + '/Cleaned_Songs')\n",
    "    except FileExistsError:  \n",
    "        pass\n",
    "    \n",
    "    for artist in artists_list_:\n",
    "        for song in artist_s_songs_list(artist):\n",
    "            f = open(dir_given + r'/' +  song, 'rb')\n",
    "            all_words = ''\n",
    "            for sentence in f.readlines():\n",
    "                this_sentence = sentence.decode('utf-8')\n",
    "                all_words += this_sentence\n",
    "            #remove identifiers like chorus, verse, etc\n",
    "            all_words = re.sub(r'[\\(\\[],.*?[\\)\\]]', '', all_words)\n",
    "            #remove empty lines\n",
    "            all_words = os.linesep.join([s for s in all_words.splitlines() if s])\n",
    "            f.close()\n",
    "            directory = \"Lyrics/Cleaned_Songs\"\n",
    "            f = open(os.path.join(dir_given + '/Cleaned_Songs', 'cleaned_' + song ), \"wb\")\n",
    "            f.write(all_words.encode('utf-8'))\n",
    "            f.close()\n",
    "    return\n",
    "\n",
    "# song_cleaning()\n",
    "\n",
    "def artist_s_cleaned_songs_list(str)->list:\n",
    "    artist_s_cleaned_songs_list_ = []\n",
    "    for cleaned_raw_filename in os.listdir(dir_given + '/Cleaned_Songs/'):\n",
    "        if cleaned_raw_filename.endswith(str + '.txt') is True:\n",
    "            if cleaned_raw_filename.endswith(str + '.txt') not in artist_s_cleaned_songs_list_:\n",
    "                artist_s_cleaned_songs_list_.append(cleaned_raw_filename)\n",
    "    return artist_s_cleaned_songs_list_\n",
    "\n",
    "# artist_s_cleaned_songs_list(\"The Beatles\")\n",
    "\n",
    "# def song_translating(artists_list):\n",
    "#     for artist in set(artists_list):\n",
    "#         for song in artist_s_songs_list(artist):\n",
    "#             #Changed below to base on single given directory\n",
    "#             f = open(dir_given + r'/Cleaned_Songs/cleaned_' +  song, 'rb')\n",
    "#             all_words = ''\n",
    "#             cleaned_songs_directory = dir_given + \"/Cleaned_Songs/\"\n",
    "\n",
    "#             for sentence in f.readlines():\n",
    "#                 this_sentence = sentence.decode('utf-8')\n",
    "#                 try:\n",
    "#                     if translator.detect(this_sentence).lang == 'en':\n",
    "#                         all_words += this_sentence\n",
    "#                     else:\n",
    "#                         translation = translator.translate(this_sentence)\n",
    "#                         all_words += translation.text\n",
    "#                 except:\n",
    "#                     print('exception')\n",
    "#             f = open(cleaned_songs_directory + 'cleaned_' + song, 'wb')\n",
    "#             f.write(all_words.encode('utf-8'))\n",
    "#             f.close()\n",
    "#     return\n",
    "\n",
    "# song_translating(artists_list())\n",
    "            \n",
    "def id_song_to_be_scored(song_to_be_scored):\n",
    "\n",
    "    f = open(dir_given + '/Cleaned_Songs/' + song_to_be_scored , 'rb')\n",
    "#     cleaned_song_name = song_to_be_scored.split(\"cleaned_\")[1].split(\"~\")[1]\n",
    "    id_song_to_be_scored = int(song_to_be_scored.split(\"cleaned_\")[1].split(\"~\")[0])\n",
    "\n",
    "    return id_song_to_be_scored\n",
    "\n",
    "# a = id_song_to_be_scored('cleaned_688~I Wanna Be Loved~Buy This Song.txt')\n",
    "\n",
    "# print('id:', a)\n",
    "\n",
    "def artist_song_to_be_scored(song_to_be_scored):\n",
    "\n",
    "    f = open(dir_given + '/Cleaned_Songs/' + song_to_be_scored , 'rb')\n",
    "    artist_song_to_be_scored = song_to_be_scored.split(\"~\")[2].split(\".txt\")[0]\n",
    "    \n",
    "    return artist_song_to_be_scored\n",
    "\n",
    "# b = artist_song_to_be_scored('cleaned_688~I Wanna Be Loved~Buy This Song.txt')\n",
    "\n",
    "# print('artist:', b)\n",
    "\n",
    "def title_song_to_be_scored(song_to_be_scored):\n",
    "\n",
    "    f = open(dir_given + '/Cleaned_Songs/' + song_to_be_scored , 'rb')\n",
    "    title_song_to_be_scored = song_to_be_scored.split(\"~\")[1].split(\".txt\")[0]\n",
    "    \n",
    "    return title_song_to_be_scored\n",
    "\n",
    "# c = title_song_to_be_scored('cleaned_688~I Wanna Be Loved~Buy This Song.txt')\n",
    "\n",
    "# print('title:', c)\n",
    "\n",
    "def profanity_score_min_max():\n",
    "#     https://github.com/vzhou842/profanity-check\n",
    "    profanity_score_list_ = []\n",
    "\n",
    "    for artist in set(artists_list()):\n",
    "        for song in artist_s_cleaned_songs_list(artist):\n",
    "            words_of_lyrics = []\n",
    "            raw_text = \"\" \n",
    "            f = open(dir_given + '/Cleaned_Songs/' + song , 'rb')\n",
    "            for line in f.readlines():\n",
    "                this_line_wordlist = line.decode('utf-8').split()\n",
    "                for word in this_line_wordlist:\n",
    "                    words_of_lyrics.append(word)\n",
    "            for word_ in words_of_lyrics:\n",
    "                raw_text += word_+\" \"\n",
    "\n",
    "            song_lyrics_for_profanity_check_ = [raw_text]\n",
    "            profanity_check = predict_prob(song_lyrics_for_profanity_check_)\n",
    "            profanity_score = 1-float(' '.join(map(str, profanity_check)))\n",
    "            profanity_score_list_.append(profanity_score)\n",
    "                \n",
    "    min_profanity_score_list_ = round(min(profanity_score_list_),2)\n",
    "    max_profanity_score_list_ = round(max(profanity_score_list_),2)\n",
    "\n",
    "    return min_profanity_score_list_, max_profanity_score_list_\n",
    "\n",
    "# d,e = profanity_score_min_max()\n",
    "\n",
    "# print('profanity score: min=', d, ',', 'max=', e)\n",
    "\n",
    "# profanity_score_min, profanity_score_max = profanity_score_min_max()\n",
    "\n",
    "def profanity_score(song_to_be_scored):\n",
    "#     https://github.com/vzhou842/profanity-check\n",
    "    words_of_lyrics_of_song_to_be_scored = []\n",
    "    raw_text = \"\" \n",
    "\n",
    "    f = open(dir_given + '/Cleaned_Songs/' + song_to_be_scored , 'rb')\n",
    "    for line in f.readlines():\n",
    "        this_line_wordlist = line.decode('utf-8').split()\n",
    "        for word in this_line_wordlist:\n",
    "            words_of_lyrics_of_song_to_be_scored.append(word)\n",
    "    for word_ in words_of_lyrics_of_song_to_be_scored:\n",
    "        raw_text += word_+\" \"\n",
    "    \n",
    "    song_lyrics_for_profanity_check_of_song_to_be_scored = [raw_text]\n",
    "    profanity_check = predict_prob(song_lyrics_for_profanity_check_of_song_to_be_scored)\n",
    "    profanity_score_of_song_to_be_scored = 1-float(' '.join(map(str, profanity_check)))\n",
    "\n",
    "    regularization_step = (profanity_score_of_song_to_be_scored - profanity_score_min)/(profanity_score_max - profanity_score_min) \n",
    "    profanity_score_of_song_to_be_scored_regularized = 1*regularization_step + 0*(1-regularization_step)\n",
    "\n",
    "    return round(profanity_score_of_song_to_be_scored_regularized,4)\n",
    "\n",
    "# f = profanity_score('cleaned_688~I Wanna Be Loved~Buy This Song.txt')\n",
    "\n",
    "# print('profanity score=', f)\n",
    "\n",
    "def love_score_min_max():\n",
    "    love_words_list_ = [\n",
    "                   'adore', 'adores', 'adorable', 'affection', 'amour', 'angel', 'bliss', \n",
    "                   'care', 'caring', 'chocolate', 'companion', 'compassion', 'concern', \n",
    "                   'darling', 'dear', 'desire', 'devotion', 'endearment', 'family', \n",
    "                   'fondness', 'forever', 'friendship', 'fun', 'God', 'happiness', 'happy', \n",
    "                   'happily', 'heart', 'hugs', 'husband', 'infatuation', 'inspiration', \n",
    "                   'intimacy', 'joy', 'kiss', 'kissed', 'kisses', \n",
    "                   'love', 'loves', 'loved', 'loving', \n",
    "                   'loyalty', 'marriage', 'passion', 'relationship', 'romance', 'sex', \n",
    "                   'sweet', 'sweetheart', 'tenderness', 'trust', 'warmth', 'wife'\n",
    "                    ]\n",
    "    love_score_list_ = []\n",
    "\n",
    "    for artist in set(artists_list()):   \n",
    "\n",
    "        for song in artist_s_cleaned_songs_list(artist):\n",
    "            words_of_lyrics = []\n",
    "            f = open(dir_given + '/Cleaned_Songs/' + song , 'rb')\n",
    "            counter_for_love_words = 0\n",
    "            for line in f.readlines():\n",
    "                this_line_wordlist = line.decode('utf-8').split()\n",
    "                for word in this_line_wordlist:\n",
    "                    words_of_lyrics.append(word)\n",
    "                    \n",
    "            filtered_words = [word for word in words_of_lyrics if word not in stopwords.words('english') and len(word) > 1 and word not in ['na','la']] # remove the stopwords\n",
    "            for item in filtered_words:\n",
    "                if item in love_words_list_:\n",
    "                    counter_for_love_words += 1\n",
    "            len_counter_for_love_words = len(love_words_list_)\n",
    "            love_score = counter_for_love_words/len(filtered_words)\n",
    "            love_score_rounded = round(love_score,4)\n",
    "            love_score_list_.append(love_score_rounded) \n",
    "            \n",
    "    min_love_score_list_ = round(min(love_score_list_),4)\n",
    "    max_love_score_list_ = round(max(love_score_list_),4)\n",
    "\n",
    "    return min_love_score_list_, max_love_score_list_\n",
    "\n",
    "# g,h = love_score_min_max()\n",
    "\n",
    "# print('love score: min=', g, ',', 'max=', h)\n",
    "\n",
    "# love_score_min, love_score_max = love_score_min_max()\n",
    "\n",
    "def love_score(song_to_be_scored):\n",
    "    \n",
    "    love_words_list_ = [\n",
    "                   'adore', 'adores', 'adorable', 'affection', 'amour', 'angel', 'bliss', \n",
    "                   'care', 'caring', 'chocolate', 'companion', 'compassion', 'concern', \n",
    "                   'darling', 'dear', 'desire', 'devotion', 'endearment', 'family', \n",
    "                   'fondness', 'forever', 'friendship', 'fun', 'God', 'happiness', 'happy', \n",
    "                   'happily', 'heart', 'hugs', 'husband', 'infatuation', 'inspiration', \n",
    "                   'intimacy', 'joy', 'kiss', 'kissed', 'kisses', \n",
    "                   'love', 'loves', 'loved', 'loving', \n",
    "                   'loyalty', 'marriage', 'passion', 'relationship', 'romance', 'sex', \n",
    "                   'sweet', 'sweetheart', 'tenderness', 'trust', 'warmth', 'wife'\n",
    "                    ]\n",
    "    words_of_lyrics_of_song_to_be_scored = []\n",
    "    f = open(dir_given + '/Cleaned_Songs/' + song_to_be_scored , 'rb')\n",
    "    counter_for_love_words = 0\n",
    "    for line in f.readlines():\n",
    "        this_line_wordlist = line.decode('utf-8').split()\n",
    "        for word in this_line_wordlist:\n",
    "            words_of_lyrics_of_song_to_be_scored.append(word)\n",
    "    filtered_words = [word for word in words_of_lyrics_of_song_to_be_scored if word not in stopwords.words('english') and len(word) > 1 and word not in ['na','la']] # remove the stopwords\n",
    "    for item in filtered_words:\n",
    "        if item in love_words_list_:\n",
    "            counter_for_love_words += 1\n",
    "#     len_counter_for_love_words = len(love_words_list_)\n",
    "    love_score_of_song_to_be_scored = counter_for_love_words/len(filtered_words)\n",
    "    love_score_of_song_to_be_scored_rounded = round(love_score_of_song_to_be_scored,4)\n",
    "    \n",
    "    regularization_step = (love_score_of_song_to_be_scored_rounded - love_score_min)/(love_score_max - love_score_min) \n",
    "    love_score_of_song_to_be_scored_rounded_regularized = 1*regularization_step + 0*(1-regularization_step)\n",
    "\n",
    "    return round(love_score_of_song_to_be_scored_rounded_regularized,4)\n",
    "\n",
    "# i = love_score('cleaned_688~I Wanna Be Loved~Buy This Song.txt')\n",
    "\n",
    "# print('love score=', i)\n",
    "\n",
    "def mood_score_min_max()->float:\n",
    "\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    mood_score_list_ = []\n",
    "\n",
    "    for artist in set(artists_list()):   \n",
    "\n",
    "        for song in artist_s_cleaned_songs_list(artist):\n",
    "            words_of_lyrics = []\n",
    "            raw_text = \"\" \n",
    "            f = open(dir_given + '/Cleaned_Songs/' + song , 'rb')\n",
    "            for line in f.readlines():\n",
    "                this_line_wordlist = line.decode('utf-8').split()         \n",
    "                for word in this_line_wordlist:\n",
    "                    words_of_lyrics.append(word)\n",
    "            for word_ in words_of_lyrics:\n",
    "                raw_text += word_+\" \"\n",
    "            mood_score_uncompounded = sid.polarity_scores(raw_text)\n",
    "            mood_score_compounded = mood_score_uncompounded['compound']\n",
    "            mood_score_compounded_rounded = round(mood_score_compounded,2)\n",
    "            mood_score_list_.append(mood_score_compounded_rounded) \n",
    "            \n",
    "    min_mood_score_list_ = round(min(mood_score_list_),4)\n",
    "    max_mood_score_list_ = round(max(mood_score_list_),4)\n",
    "\n",
    "    return min_mood_score_list_, max_mood_score_list_\n",
    "\n",
    "# j,k = mood_score_min_max()\n",
    "\n",
    "# print('mood score: min=', j, ',', 'max=', k)\n",
    "\n",
    "# mood_score_min, mood_score_max = mood_score_min_max()\n",
    "\n",
    "def mood_score(song_to_be_scored)->float:\n",
    "    \n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    words_of_lyrics_of_song_to_be_scored = []\n",
    "    raw_text = \"\"\n",
    "\n",
    "    f = open(dir_given + '/Cleaned_Songs/' + song_to_be_scored , 'rb')\n",
    "    for line in f.readlines():\n",
    "        this_line_wordlist = line.decode('utf-8').split()\n",
    "        for word in this_line_wordlist:\n",
    "            words_of_lyrics_of_song_to_be_scored.append(word)\n",
    "    for word_ in words_of_lyrics_of_song_to_be_scored:\n",
    "        raw_text += word_+\" \"\n",
    "    mood_score_uncompounded_of_song_to_be_scored = sid.polarity_scores(raw_text)\n",
    "    mood_score_compounded_of_song_to_be_scored = mood_score_uncompounded_of_song_to_be_scored['compound']\n",
    "    mood_score_compounded_of_song_to_be_scored_rounded = round(mood_score_compounded_of_song_to_be_scored,2)\n",
    "    \n",
    "    regularization_step = (mood_score_compounded_of_song_to_be_scored_rounded - mood_score_min)/(mood_score_max - mood_score_min) \n",
    "    mood_score_compounded_of_song_to_be_scored_rounded_regularized = 1*regularization_step + 0*(1-regularization_step)\n",
    "    \n",
    "    return round(mood_score_compounded_of_song_to_be_scored_rounded_regularized, 4)\n",
    "\n",
    "# l = mood_score('cleaned_688~I Wanna Be Loved~Buy This Song.txt')\n",
    "\n",
    "# print('mood score=', l)\n",
    "\n",
    "def length_score_min_max():\n",
    "\n",
    "    length_score_list_ = []\n",
    "\n",
    "    for artist in set(artists_list()):   \n",
    "        for song in artist_s_cleaned_songs_list(artist):\n",
    "                \n",
    "            num_words = 0\n",
    "    \n",
    "            f = open(dir_given + '/Cleaned_Songs/' + song , 'rb')\n",
    "            for line in f.readlines():\n",
    "                this_line_wordlist = line.decode('utf-8').split()\n",
    "                num_words += len(this_line_wordlist)\n",
    "            length_score_list_.append(num_words)\n",
    "            \n",
    "    min_length_score_list_ = min(length_score_list_)\n",
    "    max_length_score_list_ = max(length_score_list_)\n",
    "                \n",
    "    return min_length_score_list_, max_length_score_list_\n",
    "\n",
    "# m,n = length_score_min_max()\n",
    "\n",
    "# print('length score: min=', m, ',', 'max=', n)\n",
    "\n",
    "# length_score_min, length_score_max = length_score_min_max()\n",
    "\n",
    "\n",
    "def length_score(song_to_be_scored):\n",
    "    \n",
    "    num_words_of_song_to_be_scored = 0\n",
    "    f = open(dir_given + '/Cleaned_Songs/' + song_to_be_scored , 'rb')\n",
    "    for line in f.readlines():\n",
    "        this_line_wordlist = line.decode('utf-8').split()            \n",
    "        num_words_of_song_to_be_scored += len(this_line_wordlist)\n",
    "\n",
    "    length_score_of_song_to_be_scored = num_words_of_song_to_be_scored\n",
    "    \n",
    "    regularization_step = (length_score_of_song_to_be_scored - length_score_min)/(length_score_max - length_score_min) \n",
    "    length_score_of_song_to_be_scored_regularized = 1*regularization_step + 0*(1-regularization_step)\n",
    "\n",
    "    return round(length_score_of_song_to_be_scored_regularized,2)\n",
    "\n",
    "# o = length_score('cleaned_688~I Wanna Be Loved~Buy This Song.txt')\n",
    "\n",
    "# print('length score=', o)\n",
    "\n",
    "def complexity_score_min_max():\n",
    "\n",
    "    complexity_score_list_ = []\n",
    "\n",
    "    for artist in set(artists_list()):   \n",
    "        for song in artist_s_cleaned_songs_list(artist):\n",
    "                    \n",
    "            num_words = 0\n",
    "            words_of_lyrics = []\n",
    "\n",
    "            f = open(dir_given + '/Cleaned_Songs/' + song , 'rb')\n",
    "            for line in f.readlines():\n",
    "                this_line_wordlist = line.decode('utf-8').split()            \n",
    "                num_words += len(this_line_wordlist)\n",
    "                for word_ in this_line_wordlist:\n",
    "                    words_of_lyrics.append(word_)\n",
    "            \n",
    "            filtered_words = [word for word in words_of_lyrics if word not in stopwords.words('english') and len(word) > 1 and word not in ['na','la']] # remove the stopwords\n",
    "            unique_number_of_words = len(set(filtered_words))\n",
    "            number_of_words = len(words_of_lyrics)\n",
    "            complexity_score = unique_number_of_words/number_of_words\n",
    "            complexity_score = round(complexity_score,2)\n",
    "            complexity_score_list_.append(complexity_score)\n",
    "                        \n",
    "    min_complexity_score_list_ = min(set(complexity_score_list_))\n",
    "    max_complexity_score_list_ = max(set(complexity_score_list_))\n",
    "                                    \n",
    "    return min_complexity_score_list_, max_complexity_score_list_\n",
    "\n",
    "# p,q = complexity_score_min_max()\n",
    "\n",
    "# print('complexity score: min=', p, ',', 'max=', q)\n",
    "\n",
    "# complexity_score_min, complexity_score_max = complexity_score_min_max()\n",
    "\n",
    "\n",
    "def complexity_score(song_to_be_scored):\n",
    "    \n",
    "    num_words_of_song_to_be_scored = 0\n",
    "    words_of_lyrics_of_song_to_be_scored = []\n",
    "    \n",
    "    f = open(dir_given + '/Cleaned_Songs/' + song_to_be_scored , 'rb')\n",
    "    for line in f.readlines():\n",
    "        this_line_wordlist = line.decode('utf-8').split()            \n",
    "        num_words_of_song_to_be_scored += len(this_line_wordlist)\n",
    "        for word_ in this_line_wordlist:\n",
    "            words_of_lyrics_of_song_to_be_scored.append(word_)\n",
    "    \n",
    "    filtered_words_of_song_to_be_scored = [word for word in words_of_lyrics_of_song_to_be_scored if word not in stopwords.words('english') and len(word) > 1 and word not in ['na','la']] # remove the stopwords\n",
    "    unique_number_of_words_of_song_to_be_scored = len(set(filtered_words_of_song_to_be_scored))\n",
    "    number_of_words_of_song_to_be_scored = len(words_of_lyrics_of_song_to_be_scored)\n",
    "    complexity_score_of_song_to_be_scored = unique_number_of_words_of_song_to_be_scored/number_of_words_of_song_to_be_scored\n",
    "    complexity_score_of_song_to_be_scored = round(complexity_score_of_song_to_be_scored,2)\n",
    "    \n",
    "    regularization_step = (complexity_score_of_song_to_be_scored - complexity_score_min)/(complexity_score_max - complexity_score_min) \n",
    "    complexity_score_of_song_to_be_scored_regularized = 1*regularization_step + 0*(1-regularization_step)\n",
    "\n",
    "    return round(complexity_score_of_song_to_be_scored_regularized, 2)\n",
    "\n",
    "# r = complexity_score('cleaned_688~I Wanna Be Loved~Buy This Song.txt')\n",
    "\n",
    "# print('complexity score=', r)\n",
    "\n",
    "# cell_t = time.time()\n",
    "# print(cell_t - cell_s_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# cell_s_t = time.time()\n",
    "\n",
    "def json_creation():\n",
    "    dict_for_json = {}\n",
    "    for artist in set(artists_list()):   \n",
    "        for song in artist_s_cleaned_songs_list(artist):\n",
    "            dict_for_json_song = {}\n",
    "            dict_for_json_song[\"id\"] = id_song_to_be_scored(song)\n",
    "            dict_for_json_song[\"artist\"] = artist\n",
    "            dict_for_json_song[\"title\"] = title_song_to_be_scored(song)        \n",
    "            dict_for_json_song[\"kids_safe\"] = profanity_score(song)\n",
    "            dict_for_json_song[\"love\"] = love_score(song)\n",
    "            dict_for_json_song[\"mood\"] = mood_score(song)\n",
    "            dict_for_json_song[\"length\"] = length_score(song)\n",
    "            dict_for_json_song[\"complexity\"] = complexity_score(song)\n",
    "            dict_for_json.setdefault('characterizations:', []).append(dict_for_json_song)\n",
    "    print(json.dumps(dict_for_json, indent=4))\n",
    "\n",
    "# Checking that all the songs are given a characterization:\n",
    "\n",
    "    print(len(dict_for_json['characterizations:']))\n",
    "\n",
    "# cell_t = time.time()\n",
    "# print(cell_t - cell_s_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    global artists_list_, raw_filenames_list_, profanity_score_min, profanity_score_max, love_score_min, love_score_max, mood_score_min, mood_score_max, length_score_min, length_score_max, complexity_score_min, complexity_score_max\n",
    "    artists_list_ = artists_list()\n",
    "    raw_filenames_list_ = raw_filenames_list()\n",
    "    song_cleaning()\n",
    "    profanity_score_min, profanity_score_max = profanity_score_min_max()\n",
    "    love_score_min, love_score_max = love_score_min_max()\n",
    "    mood_score_min, mood_score_max = mood_score_min_max()\n",
    "    length_score_min, length_score_max = length_score_min_max()\n",
    "    complexity_score_min, complexity_score_max = complexity_score_min_max()\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dir_given = r'C:\\Users\\Kyle_Shipley\\Documents\\Columbia_Docs\\IEOR 4501\\ProjectTemp\\TFA_Project-Alex2\\TFA_Project-Alex\\Lyrics'\n",
    "    os.chdir(dir_given)\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_creation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unit Testing File\n",
    "\n",
    "#import main.py as m\n",
    "\n",
    "#check that title for song 997 is correct\n",
    "class TestFuncOutputs(unittest.TestCase):\n",
    "\n",
    "    def test_art_list(self):\n",
    "        art_ls = artists_list()\n",
    "        self.assertTrue(isinstance(art_ls, list))\n",
    "        \n",
    "    def test_raw_list(self):\n",
    "        raw_ls = raw_filenames_list()\n",
    "        self.assertTrue(isinstance(raw_ls, list))\n",
    "        \n",
    "    def test_artist_s_songs_list(self):\n",
    "        self.assertEqual(len(artist_s_songs_list(\"Buy This Song\")), 23)\n",
    "        \n",
    "#     def test_cleaning(self):\n",
    "#         song_cleaning()\n",
    "#         self.assertTrue(os.path.exists(dir_given + '/Cleaned_Songs/' + \"cleaned_688~I Wanna Be Loved~Buy This Song.txt\"))\n",
    "\n",
    "    def test_artist_s_cleaned_songs_list(self):\n",
    "        self.assertEqual(len(artist_s_cleaned_songs_list(\"Buy This Song\")), 23)\n",
    "\n",
    "    def test_ids(self):\n",
    "        self.assertEqual(id_song_to_be_scored('cleaned_688~I Wanna Be Loved~Buy This Song.txt'), 688)\n",
    "\n",
    "    def test_artist(self):\n",
    "        self.assertEqual(artist_song_to_be_scored('cleaned_688~I Wanna Be Loved~Buy This Song.txt'), \"Buy This Song\")\n",
    "        \n",
    "    def test_title(self):\n",
    "        self.assertEqual(title_song_to_be_scored('cleaned_688~I Wanna Be Loved~Buy This Song.txt'), \"I Wanna Be Loved\")\n",
    "        \n",
    "    def test_kid_safe(self):\n",
    "        self.assertEqual(profanity_score('cleaned_688~I Wanna Be Loved~Buy This Song.txt'), 0.9683)\n",
    "        \n",
    "    def test_love(self):\n",
    "        self.assertEqual(love_score('cleaned_688~I Wanna Be Loved~Buy This Song.txt'), 0.4536)\n",
    "        \n",
    "    def test_mood(self):\n",
    "        self.assertEqual(mood_score('cleaned_688~I Wanna Be Loved~Buy This Song.txt'), 1.0)\n",
    "        \n",
    "    def test_length(self):\n",
    "        self.assertEqual(length_score('cleaned_688~I Wanna Be Loved~Buy This Song.txt'), 0.17)\n",
    "        \n",
    "    def test_complexity(self):\n",
    "        self.assertEqual(complexity_score('cleaned_688~I Wanna Be Loved~Buy This Song.txt'), 0.27)\n",
    "\n",
    "def main():\n",
    "    suite = unittest.defaultTestLoader.loadTestsFromTestCase(TestFuncOutputs)\n",
    "    unittest.TextTestRunner().run(suite)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "#     m.imports()\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running\n"
     ]
    }
   ],
   "source": [
    "#                     if translator.detect(this_sentence).lang == 'en':\n",
    "#                         all_words += this_sentence\n",
    "#                     else:\n",
    "#                         translation = translator.translate(this_sentence)\n",
    "#                         all_words += translation.text\n",
    "#                 except:\n",
    "#                     pass\n",
    " \n",
    "#             f.close()\n",
    "#             #Deleted Directory variable and modified below line to take given directory\n",
    "#             f = open(dir_given + r'/Cleaned_Songs/cleaned_' +  song, 'wb')\n",
    "#             f.write(all_words.encode('utf-8'))\n",
    "#             f.close()\n",
    "# %time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
